{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Librairies importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self, num_inp, num_hid, num_out):\n",
    "        super(MNIST_MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(num_inp, num_hid)\n",
    "        self.layer2 = nn.Linear(num_hid, num_out)\n",
    "\n",
    "    def initialize(self):\n",
    "        nn.init.kaiming_uniform_(self.layer1.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.layer2.weight, a=math.sqrt(5))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Compute a prediction.\"\"\"\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.layer1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, data_loader, device):\n",
    "    model = copy.deepcopy(model)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        #print(i)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataset, test_dataset, optimizer, batch_sizes, target_acc, epoch, loss_fn, device):\n",
    "    model.train()\n",
    "    steps = []\n",
    "    # Train the model for different batch sizes\n",
    "    for batch_size in batch_sizes:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "        # Re initialize the model\n",
    "        model.initialize()\n",
    "        step = 0\n",
    "        # Value to know if we must change the batch size\n",
    "        new_batch = False\n",
    "        for i in range(epoch):\n",
    "            if new_batch:\n",
    "                break\n",
    "            loss_epoch = 0\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                #print(batch_idx)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "\n",
    "                # Check to know if at step k, the accuracy is greater than the target accuracy\n",
    "                accuracy = validation(model, test_loader, device)\n",
    "                #print(accuracy)\n",
    "                if accuracy >= target_acc:\n",
    "                    print('Validation accuracy = {:.6f} reached at step {}'.format(accuracy, step))\n",
    "                    steps.append(step)\n",
    "                    new_batch = True\n",
    "                    break\n",
    "\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                loss_epoch += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                step += 1\n",
    "            \n",
    "            loss_epoch /= len(train_loader)\n",
    "\n",
    "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                i, loss_epoch))\n",
    "\n",
    "    return steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tLoss: 1.407031\n",
      "Train Epoch: 1 \tLoss: 1.123443\n",
      "Train Epoch: 2 \tLoss: 1.064043\n",
      "Validation accuracy = 0.902344 reached at step 6052\n",
      "Train Epoch: 3 \tLoss: 0.238702\n",
      "Train Epoch: 0 \tLoss: 1.568031\n",
      "Train Epoch: 1 \tLoss: 1.231590\n",
      "Train Epoch: 2 \tLoss: 1.146510\n",
      "Train Epoch: 3 \tLoss: 1.100990\n",
      "Train Epoch: 4 \tLoss: 1.072651\n",
      "Train Epoch: 5 \tLoss: 1.053330\n",
      "Train Epoch: 6 \tLoss: 1.039047\n",
      "Train Epoch: 7 \tLoss: 1.027795\n",
      "Validation accuracy = 0.902344 reached at step 7547\n",
      "Train Epoch: 8 \tLoss: 0.047121\n",
      "Train Epoch: 0 \tLoss: 1.750638\n",
      "Train Epoch: 1 \tLoss: 1.363983\n",
      "Train Epoch: 2 \tLoss: 1.253322\n",
      "Train Epoch: 3 \tLoss: 1.193578\n",
      "Train Epoch: 4 \tLoss: 1.154464\n",
      "Train Epoch: 5 \tLoss: 1.126550\n",
      "Train Epoch: 6 \tLoss: 1.105714\n",
      "Train Epoch: 7 \tLoss: 1.089427\n",
      "Train Epoch: 8 \tLoss: 1.076283\n",
      "Train Epoch: 9 \tLoss: 1.065530\n",
      "Train Epoch: 10 \tLoss: 1.056469\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mazet\\OneDrive\\Documents\\Telecom Paris\\ETH\\Deep Learning\\Parameters-is-all-you-need\\batch_size\\batch_size.ipynb Cell 10\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Experimentation with non hyper-optimized SGD\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# No momentum to focus on the learning rate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m steps \u001b[39m=\u001b[39m training(model, train_dataset, test_dataset, optimizer, batch_sizes, target_acc, epoch, loss_fn, DEVICE)\n",
      "\u001b[1;32mc:\\Users\\mazet\\OneDrive\\Documents\\Telecom Paris\\ETH\\Deep Learning\\Parameters-is-all-you-need\\batch_size\\batch_size.ipynb Cell 10\u001b[0m line \u001b[0;36mtraining\u001b[1;34m(model, train_dataset, test_dataset, optimizer, batch_sizes, target_acc, epoch, loss_fn, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss_epoch \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m#print(batch_idx)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\mazet\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:174\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    172\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch_sizes = [1, 2, 2**2, 2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9]\n",
    "batch_sizes = [2**5, 2**6, 2**7, 2**8, 2**9]\n",
    "target_acc = 0.9\n",
    "epoch = 40\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# Keep only n samples for validation\n",
    "n = 256\n",
    "test_dataset, _ = torch.utils.data.random_split(test_dataset, [n, len(test_dataset) - n])\n",
    "\n",
    "# Initialize the model\n",
    "model = MNIST_MLP(28*28, 128, 10).to(DEVICE)\n",
    "model.initialize()\n",
    "\n",
    "# Experimentation with non hyper-optimized SGD\n",
    "# No momentum to focus on the learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Experiments several times to get robust results\n",
    "iter = 10\n",
    "mean_steps = [0] * len(batch_sizes)\n",
    "for i in range(iter):\n",
    "    steps = training(model, train_dataset, test_dataset, optimizer, batch_sizes, target_acc, epoch, loss_fn, DEVICE)\n",
    "    mean_steps = [x + y for x, y in zip(mean_steps, steps)]\n",
    "mean_steps = [x / iter for x in mean_steps]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[842, 829, 806, 889, 1152]\n"
     ]
    }
   ],
   "source": [
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the steps vs batch size\n",
    "plt.plot(batch_sizes, steps)\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=2)\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Number of steps')\n",
    "plt.title('Number of steps vs batch size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mazet\\OneDrive\\Documents\\Telecom Paris\\ETH\\Deep Learning\\Parameters-is-all-you-need\\batch_size\\batch_size.ipynb Cell 14\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save the list to a file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmy_list.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(my_list, f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load the list from the file\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mazet/OneDrive/Documents/Telecom%20Paris/ETH/Deep%20Learning/Parameters-is-all-you-need/batch_size/batch_size.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmy_list.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the list to a file\n",
    "with open('my_list.pkl', 'wb') as f:\n",
    "    pickle.dump(my_list, f)\n",
    "\n",
    "# Load the list from the file\n",
    "with open('my_list.pkl', 'rb') as f:\n",
    "    my_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
