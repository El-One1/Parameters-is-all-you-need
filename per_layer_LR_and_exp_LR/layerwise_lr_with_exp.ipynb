{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEzRJ1JoQrfE"
      },
      "source": [
        "Code based on the example at https://github.com/kach/gradient-descent-the-ultimate-optimizer\n",
        "\n",
        "### Experiments with separate learning rates per layer/per parameter, and exponential link function.\n",
        "\n",
        "Note : if you are using Colab, set COLAB=True at the end of the second cell, and run the following cell. Otherwise, simply don't run the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoASRDKZQ5dN",
        "outputId": "fb0771c9-2031-4614-e8ba-c53882ab26bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradient-descent-the-ultimate-optimizer\n",
            "  Downloading gradient_descent_the_ultimate_optimizer-1.0-py3-none-any.whl (7.3 kB)\n",
            "Installing collected packages: gradient-descent-the-ultimate-optimizer\n",
            "Successfully installed gradient-descent-the-ultimate-optimizer-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradient-descent-the-ultimate-optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "36txpOUdQrfO"
      },
      "outputs": [],
      "source": [
        "# IF AND ONLY IF YOU ARE USING COLAB, SET COLAB=True (at the end of this cell)\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gradient_descent_the_ultimate_optimizer import gdtuo\n",
        "COLAB=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XOWI50OLAoR",
        "outputId": "49073edd-53e0-401d-e62c-06e380154dea"
      },
      "outputs": [],
      "source": [
        "SAVEPATH='trainingdata/'\n",
        "PREFIX='CIFAR10-' #Set to 'CIFAR10' for CIFAR10, '' for MNIST\n",
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  SAVEPATH = '/content/drive/MyDrive/Colab Notebooks/' + SAVEPATH\n",
        "  drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eOPTqb8LLRdb"
      },
      "outputs": [],
      "source": [
        "def save_training_data(train_loss, test_acc, test_loss, name):\n",
        "  torch.save(train_loss, SAVEPATH+PREFIX+name+\"-train-loss.pth\")\n",
        "  torch.save(test_acc, SAVEPATH+PREFIX+name+\"-test-acc.pth\")\n",
        "  torch.save(test_loss, SAVEPATH+PREFIX+name+\"-test-loss.pth\")\n",
        "\n",
        "def load_training_data(name):\n",
        "  train_loss = torch.load(SAVEPATH+PREFIX+name+\"-train-loss.pth\")\n",
        "  test_acc = torch.load(SAVEPATH+PREFIX+name+\"-test-acc.pth\")\n",
        "  test_loss = torch.load(SAVEPATH+PREFIX+name+\"-test-loss.pth\")\n",
        "  return train_loss, test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jXZmAO5xEWr"
      },
      "outputs": [],
      "source": [
        "#Code adapted from gdtuo implementation of SGD\n",
        "class SGDExp(gdtuo.Optimizable):\n",
        "    '''\n",
        "    A hyperoptimizable SGD, with the option (if init with exp=True) to pass\n",
        "    the learning rate through an exponential link function to ensure its positiveness\n",
        "    and to make training more stable with regards to the \"hyper-learning rate\".\n",
        "\n",
        "    Make sure to adapt the `alpha` value depending on whether you use this option.\n",
        "    '''\n",
        "    def __init__(self, alpha=0.01, mu=0.0, optimizer=gdtuo.NoOpOptimizer(), exp=False):\n",
        "        self.mu = mu\n",
        "        self.state = {}\n",
        "        self.exp = exp\n",
        "        parameters = {\n",
        "            'alpha': torch.tensor(alpha),\n",
        "            'mu': torch.tensor(mu)\n",
        "        }\n",
        "        super().__init__(parameters, optimizer)\n",
        "\n",
        "    def step(self, params):\n",
        "        self.optimizer.step(self.parameters)\n",
        "        for name, param in params.items():\n",
        "            g = param.grad.detach()\n",
        "            p = param.detach()\n",
        "            if self.mu != 0.0:\n",
        "                if name not in self.state:\n",
        "                    buf = self.state[name] = g\n",
        "                else:\n",
        "                    buf = self.state[name].detach()\n",
        "                    buf = buf * self.parameters['mu'] + g\n",
        "                g = self.state[name] = buf\n",
        "            if self.exp:\n",
        "              params[name] = p - g * self.parameters['alpha'].exp()\n",
        "            else:\n",
        "              params[name] = p - g * self.parameters['alpha']\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'sgd / '+ str(self.optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qys5XO-2QrfS"
      },
      "outputs": [],
      "source": [
        "#Have a different learning rate for each layer\n",
        "class SGDLayerWise(gdtuo.Optimizable):\n",
        "    '''\n",
        "    Optimizes parameters with SGD using one learning rate per parameter tensor. \n",
        "    Note that the learning rate is shared between all elements of a given tensor.\n",
        "    Furthermore, this class makes the alpha parameter go through an exponential link function.\n",
        "    Thus the actual learning rate is exp(alpha). \n",
        "\n",
        "    TODO : rename lr0 to alpha0 because it is not the learning rate...\n",
        "    '''\n",
        "    def __init__(self, params, lr0=-1.0, optimizer=gdtuo.NoOpOptimizer(), device='cpu'):\n",
        "        parameters = {k + '_alpha' : torch.tensor([lr0], requires_grad=True).to(device) for k, v in params}\n",
        "        super().__init__(parameters, optimizer)\n",
        "\n",
        "    def step(self, params):\n",
        "        self.optimizer.step(self.parameters)\n",
        "        for name, param in params.items():\n",
        "            g = param.grad.detach()\n",
        "            p = param.detach()\n",
        "            if name + '_alpha' not in self.parameters: params[name] = p\n",
        "            else: params[name] = p - g * self.parameters[name + '_alpha'].exp()\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'SGDLayerWise / ' + str(self.optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNunxWxuSfky"
      },
      "outputs": [],
      "source": [
        "class SGDParamWise(gdtuo.Optimizable):\n",
        "    '''\n",
        "    Optimizes parameters with SGD using one learning rate per parameter\n",
        "    (effectively doubles the number of learnable parameters).\n",
        "\n",
        "    Furthermore, this class makes the alpha parameter go through an exponential link function.\n",
        "    Thus the actual learning rate is exp(alpha). \n",
        "\n",
        "    TODO : rename lr0 to alpha0 because it is not the learning rate...\n",
        "    '''\n",
        "    def __init__(self, params, lr0=-1.0, optimizer=gdtuo.NoOpOptimizer(), device='cpu'):\n",
        "        parameters = {k + '_alpha' : lr0 * torch.ones_like(v).to(device)\n",
        "                      for k, v in params}\n",
        "        super().__init__(parameters, optimizer)\n",
        "\n",
        "    def step(self, params):\n",
        "        self.optimizer.step(self.parameters)\n",
        "        for name, param in params.items():\n",
        "            g = param.grad.detach()\n",
        "            p = param.detach()\n",
        "            if name + '_alpha' not in self.parameters: params[name] = p\n",
        "            else: params[name] = p - g * self.parameters[name + '_alpha'].exp()\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'SGDLayerWise / ' + str(self.optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6VUeIBXQrfV",
        "outputId": "8286510f-1b2c-4690-82e5-90325e2ea755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 113832456.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 29480577.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 54549904.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5387592.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##############################\n",
        "## MNIST Model + Data\n",
        "##############################\n",
        "\n",
        "#Create the model and load the MNIST data. Don't execute this cell if you want to use CIFAR10 (run the next one instead).\n",
        "\n",
        "class MNIST_FullyConnected(nn.Module):\n",
        "    \"\"\"\n",
        "    A fully-connected NN for the MNIST task. This is Optimizable but not itself\n",
        "    an optimizer.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_inp, num_hid, num_hid2, num_hid3, num_out):\n",
        "        super(MNIST_FullyConnected, self).__init__()\n",
        "        self.layer1 = nn.Linear(num_inp, num_hid)\n",
        "        self.layer2 = nn.Linear(num_hid, num_hid2)\n",
        "        self.layer3 = nn.Linear(num_hid2, num_hid3)\n",
        "        self.layer4 = nn.Linear(num_hid3, num_out)\n",
        "\n",
        "\n",
        "    def initialize(self):\n",
        "        nn.init.kaiming_uniform_(self.layer1.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.layer2.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.layer3.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.layer4.weight, a=math.sqrt(5))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Compute a prediction.\"\"\"\n",
        "        x = self.layer1(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.layer2(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.layer3(x)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.layer4(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 10\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST('./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "mnist_test = torchvision.datasets.MNIST('./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "dl_train = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dl_test = torch.utils.data.DataLoader(mnist_test, batch_size=10000, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyVwv6XRdy2J",
        "outputId": "08c87fa0-498f-4cbc-8eda-d1c2d430aa48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 79668104.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "##############################\n",
        "## CIFAR10 Model + Data\n",
        "##############################\n",
        "\n",
        "#Create the model and load the MNIST data. Don't execute this cell if you want to use MNIST (run the previous one instead).\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.channels = channels\n",
        "\n",
        "    self.conv1 = nn.Conv2d(channels, channels, 3, padding='same')\n",
        "    self.act1 = nn.LeakyReLU()\n",
        "    self.conv2 = nn.Conv2d(channels, channels, 3, padding='same')\n",
        "    self.act2 = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.conv1(x)\n",
        "    y = self.act1(y)\n",
        "    y = self.conv2(y)\n",
        "    y = self.act2(y)\n",
        "    return y + x\n",
        "\n",
        "class CIFAR10_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 24, 3, padding='same')\n",
        "    self.act1 = nn.LeakyReLU()\n",
        "    self.res1 = ResidualBlock(24)\n",
        "    self.pooling1 = nn.MaxPool2d(2) #Nx24x16x16\n",
        "    self.res2 = ResidualBlock(24)\n",
        "    self.pooling2 = nn.MaxPool2d(2) #Nx24x8x8\n",
        "    self.fc1 = nn.Linear(1536, 128)\n",
        "    self.fc_act1 = nn.LeakyReLU()\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "    self.act_final = nn.LogSoftmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.res1(x)\n",
        "    x = self.pooling1(x)\n",
        "    x = self.res2(x)\n",
        "    x = self.pooling2(x)\n",
        "    x = self.fc1(x.view(-1, 1536))\n",
        "    x = self.fc_act1(x)\n",
        "    x = self.fc2(x)\n",
        "    return self.act_final(x)\n",
        "\n",
        "#Load and transform data\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "dl_train = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "dl_test = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 50\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suwW1QVJQrfY"
      },
      "outputs": [],
      "source": [
        "#Test the model\n",
        "def test(mw):\n",
        "  with torch.no_grad():\n",
        "      for features, labels in dl_test:\n",
        "          if PREFIX=='': #MNIST\n",
        "            features, labels = torch.reshape(features, (-1, 28 * 28)).to(DEVICE), labels.to(DEVICE)\n",
        "          else: #CIFAR10\n",
        "            features, labels = features.to(DEVICE), labels.to(DEVICE)\n",
        "          pred = mw.forward(features)\n",
        "          loss = F.nll_loss(pred, labels, reduction='sum')\n",
        "          pred = torch.argmax(pred, dim=1)\n",
        "          print(\"TEST ACCURACY: {}\".format((pred == labels).sum().item() / len(labels)))\n",
        "          break\n",
        "  return (pred == labels).sum().item() / len(labels), loss / len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC2AbdL5QrfX"
      },
      "outputs": [],
      "source": [
        "#Training loop\n",
        "def train(mw, record_data=False):\n",
        "  #Store data about the training progress\n",
        "  train_losses = []\n",
        "  test_acc = []\n",
        "  test_loss = []\n",
        "\n",
        "  for i in range(1, EPOCHS+1):\n",
        "      running_loss = 0.0\n",
        "      for n, v in mw.optimizer.parameters.items():\n",
        "          print(f\"Learning rates : {n} : mean={v.mean().item()}, std={v.std().item()}, \\\n",
        "          min={v.min().item()}, max={v.max().item()}\")\n",
        "      for j, (features_, labels_) in enumerate(dl_train):\n",
        "          mw.begin() # call this before each step, enables gradient tracking on desired params\n",
        "          #features, labels = torch.reshape(features_, (-1, 28 * 28)).to(DEVICE), labels_.to(DEVICE)\n",
        "          features, labels = features_.to(DEVICE), labels_.to(DEVICE)\n",
        "          pred = mw.forward(features)\n",
        "          loss = F.nll_loss(pred, labels)\n",
        "          mw.zero_grad()\n",
        "          loss.backward(create_graph=True) # important! use create_graph=True\n",
        "          mw.step()\n",
        "\n",
        "          running_loss += loss.item() * features_.size(0)\n",
        "          if record_data:\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "\n",
        "      train_loss = running_loss / len(dl_train.dataset)\n",
        "\n",
        "      print(\"EPOCH: {}, TRAIN LOSS: {}\".format(i, train_loss))\n",
        "      if record_data:\n",
        "        acc, l = test(mw)\n",
        "        test_acc.append(acc)\n",
        "        test_loss.append(l.item())\n",
        "  return train_losses, test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJTyXEDobLz_",
        "outputId": "302f62f3-617b-4975-c329-2352dd86232b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 1, TRAIN LOSS: 1.6644511247253417\n",
            "TEST ACCURACY: 0.4453125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 2, TRAIN LOSS: 1.2759192936325072\n",
            "TEST ACCURACY: 0.5859375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 3, TRAIN LOSS: 1.1048702878570558\n",
            "TEST ACCURACY: 0.6484375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 4, TRAIN LOSS: 0.9875966917800904\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 5, TRAIN LOSS: 0.8924553308296204\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 6, TRAIN LOSS: 0.8184503198432922\n",
            "TEST ACCURACY: 0.609375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 7, TRAIN LOSS: 0.7451064594268799\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 8, TRAIN LOSS: 0.6898010395431519\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 9, TRAIN LOSS: 0.6324759451675415\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 10, TRAIN LOSS: 0.5848600833702088\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 11, TRAIN LOSS: 0.5312418658065796\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 12, TRAIN LOSS: 0.48926830797195436\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 13, TRAIN LOSS: 0.4396776294898987\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 14, TRAIN LOSS: 0.40496856103897094\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 15, TRAIN LOSS: 0.366216596698761\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 16, TRAIN LOSS: 0.32243827198028563\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 17, TRAIN LOSS: 0.2832213876914978\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 18, TRAIN LOSS: 0.2584746311855316\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 19, TRAIN LOSS: 0.22982738604545594\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 20, TRAIN LOSS: 0.1995757089328766\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 21, TRAIN LOSS: 0.179381900305748\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 22, TRAIN LOSS: 0.1511569911623001\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 23, TRAIN LOSS: 0.13749195494174957\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 24, TRAIN LOSS: 0.10994303664207458\n",
            "TEST ACCURACY: 0.734375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 25, TRAIN LOSS: 0.11987161999702453\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 26, TRAIN LOSS: 0.11549758127689362\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 27, TRAIN LOSS: 0.06904399726390839\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 28, TRAIN LOSS: 0.06489462550878525\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 29, TRAIN LOSS: 0.08318960771083832\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 30, TRAIN LOSS: 0.07951383417010308\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 31, TRAIN LOSS: 0.053779748882055285\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 32, TRAIN LOSS: 0.03616141094923019\n",
            "TEST ACCURACY: 0.75\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 33, TRAIN LOSS: 0.02533384673714638\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 34, TRAIN LOSS: 0.010380275600850582\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 35, TRAIN LOSS: 0.0026507519491389396\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 36, TRAIN LOSS: 0.0012166461385786534\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 37, TRAIN LOSS: 0.0009004573074728251\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 38, TRAIN LOSS: 0.0007527615954913199\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 39, TRAIN LOSS: 0.0006545553627796471\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 40, TRAIN LOSS: 0.0005839654472656548\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 41, TRAIN LOSS: 0.0005273904709517956\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 42, TRAIN LOSS: 0.00048290170492604374\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 43, TRAIN LOSS: 0.0004447685662098229\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 44, TRAIN LOSS: 0.00041366554595530035\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 45, TRAIN LOSS: 0.00038596238324418666\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 46, TRAIN LOSS: 0.0003623205955512822\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 47, TRAIN LOSS: 0.00034157932193018493\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 48, TRAIN LOSS: 0.0003232608078978956\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 49, TRAIN LOSS: 0.000306833104765974\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 50, TRAIN LOSS: 0.0002918766189552844\n",
            "TEST ACCURACY: 0.71875\n"
          ]
        }
      ],
      "source": [
        "#This is the baseline, with simple SGD (so no hyperoptimization).\n",
        "\n",
        "#model_vanilla = MNIST_FullyConnected(28 * 28, 128, 16, 16, 10).to(DEVICE)\n",
        "model_vanilla = CIFAR10_CNN().to(DEVICE)\n",
        "\n",
        "#Create the optimizer\n",
        "optim_vanilla = gdtuo.SGD(alpha=math.exp(-2.0))\n",
        "mw_vanilla = gdtuo.ModuleWrapper(model_vanilla, optimizer=optim_vanilla)\n",
        "mw_vanilla.initialize()\n",
        "\n",
        "train_loss, test_acc, test_loss = train(mw_vanilla, record_data=True)\n",
        "save_training_data(train_loss, test_acc, test_loss, \"SGD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDKP25eXyCPH",
        "outputId": "7f97a95a-3d78-43d3-de60-e24b588d191a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rates : alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1, TRAIN LOSS: 1.6426028886032105\n",
            "TEST ACCURACY: 0.5390625\n",
            "Learning rates : alpha : mean=-2.6400909423828125, std=nan,           min=-2.6400909423828125, max=-2.6400909423828125\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 2, TRAIN LOSS: 1.2728037090682984\n",
            "TEST ACCURACY: 0.6328125\n",
            "Learning rates : alpha : mean=-3.0560302734375, std=nan,           min=-3.0560302734375, max=-3.0560302734375\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 3, TRAIN LOSS: 1.1373739447021485\n",
            "TEST ACCURACY: 0.6328125\n",
            "Learning rates : alpha : mean=-3.3628859519958496, std=nan,           min=-3.3628859519958496, max=-3.3628859519958496\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 4, TRAIN LOSS: 1.0457148471832276\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=-3.6173553466796875, std=nan,           min=-3.6173553466796875, max=-3.6173553466796875\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 5, TRAIN LOSS: 0.9746955237579346\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : alpha : mean=-3.837888479232788, std=nan,           min=-3.837888479232788, max=-3.837888479232788\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 6, TRAIN LOSS: 0.9199786039733887\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=-4.0282487869262695, std=nan,           min=-4.0282487869262695, max=-4.0282487869262695\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 7, TRAIN LOSS: 0.8766021154594421\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=-4.187849998474121, std=nan,           min=-4.187849998474121, max=-4.187849998474121\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 8, TRAIN LOSS: 0.8425035327339172\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-4.325747489929199, std=nan,           min=-4.325747489929199, max=-4.325747489929199\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 9, TRAIN LOSS: 0.8118659742736817\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-4.44707727432251, std=nan,           min=-4.44707727432251, max=-4.44707727432251\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 10, TRAIN LOSS: 0.7886148013687134\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-4.55918550491333, std=nan,           min=-4.55918550491333, max=-4.55918550491333\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 11, TRAIN LOSS: 0.7650806778144836\n",
            "TEST ACCURACY: 0.765625\n",
            "Learning rates : alpha : mean=-4.655539035797119, std=nan,           min=-4.655539035797119, max=-4.655539035797119\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 12, TRAIN LOSS: 0.7459614347839355\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-4.743531703948975, std=nan,           min=-4.743531703948975, max=-4.743531703948975\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 13, TRAIN LOSS: 0.7277294515800476\n",
            "TEST ACCURACY: 0.7578125\n",
            "Learning rates : alpha : mean=-4.821781635284424, std=nan,           min=-4.821781635284424, max=-4.821781635284424\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 14, TRAIN LOSS: 0.7140347803306579\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : alpha : mean=-4.909393787384033, std=nan,           min=-4.909393787384033, max=-4.909393787384033\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 15, TRAIN LOSS: 0.6978413694381714\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-4.981770038604736, std=nan,           min=-4.981770038604736, max=-4.981770038604736\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 16, TRAIN LOSS: 0.6833750885391235\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.044353485107422, std=nan,           min=-5.044353485107422, max=-5.044353485107422\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 17, TRAIN LOSS: 0.670666301612854\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.096566200256348, std=nan,           min=-5.096566200256348, max=-5.096566200256348\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 18, TRAIN LOSS: 0.6588521572494507\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.151874542236328, std=nan,           min=-5.151874542236328, max=-5.151874542236328\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 19, TRAIN LOSS: 0.6478209929275512\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-5.203914642333984, std=nan,           min=-5.203914642333984, max=-5.203914642333984\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 20, TRAIN LOSS: 0.637922171459198\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.259981155395508, std=nan,           min=-5.259981155395508, max=-5.259981155395508\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 21, TRAIN LOSS: 0.6267063259887695\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-5.304869651794434, std=nan,           min=-5.304869651794434, max=-5.304869651794434\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 22, TRAIN LOSS: 0.6172343759346008\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : alpha : mean=-5.354367733001709, std=nan,           min=-5.354367733001709, max=-5.354367733001709\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 23, TRAIN LOSS: 0.607642037525177\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : alpha : mean=-5.39738130569458, std=nan,           min=-5.39738130569458, max=-5.39738130569458\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 24, TRAIN LOSS: 0.5992485361480713\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : alpha : mean=-5.439338684082031, std=nan,           min=-5.439338684082031, max=-5.439338684082031\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 25, TRAIN LOSS: 0.5900189707946777\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.484677791595459, std=nan,           min=-5.484677791595459, max=-5.484677791595459\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 26, TRAIN LOSS: 0.5823824318885803\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.529682159423828, std=nan,           min=-5.529682159423828, max=-5.529682159423828\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 27, TRAIN LOSS: 0.5736204813766479\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.56947660446167, std=nan,           min=-5.56947660446167, max=-5.56947660446167\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 28, TRAIN LOSS: 0.5666024624061584\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : alpha : mean=-5.606600761413574, std=nan,           min=-5.606600761413574, max=-5.606600761413574\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 29, TRAIN LOSS: 0.5587087896919251\n",
            "TEST ACCURACY: 0.7578125\n",
            "Learning rates : alpha : mean=-5.645557880401611, std=nan,           min=-5.645557880401611, max=-5.645557880401611\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 30, TRAIN LOSS: 0.5514013347434997\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : alpha : mean=-5.680898189544678, std=nan,           min=-5.680898189544678, max=-5.680898189544678\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 31, TRAIN LOSS: 0.5445078867530823\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.716427803039551, std=nan,           min=-5.716427803039551, max=-5.716427803039551\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 32, TRAIN LOSS: 0.5377331595230103\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.751484394073486, std=nan,           min=-5.751484394073486, max=-5.751484394073486\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 33, TRAIN LOSS: 0.5303636717796326\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.785607814788818, std=nan,           min=-5.785607814788818, max=-5.785607814788818\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 34, TRAIN LOSS: 0.5245048782920837\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : alpha : mean=-5.817300796508789, std=nan,           min=-5.817300796508789, max=-5.817300796508789\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 35, TRAIN LOSS: 0.518700406665802\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.851955890655518, std=nan,           min=-5.851955890655518, max=-5.851955890655518\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 36, TRAIN LOSS: 0.5123440066719055\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : alpha : mean=-5.881226062774658, std=nan,           min=-5.881226062774658, max=-5.881226062774658\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 37, TRAIN LOSS: 0.5069844730854034\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : alpha : mean=-5.911141395568848, std=nan,           min=-5.911141395568848, max=-5.911141395568848\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 38, TRAIN LOSS: 0.4998564298248291\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-5.938700199127197, std=nan,           min=-5.938700199127197, max=-5.938700199127197\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 39, TRAIN LOSS: 0.4947492502975464\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.965812683105469, std=nan,           min=-5.965812683105469, max=-5.965812683105469\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 40, TRAIN LOSS: 0.48912276594161985\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-5.990459442138672, std=nan,           min=-5.990459442138672, max=-5.990459442138672\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 41, TRAIN LOSS: 0.48413905700683596\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-6.014090061187744, std=nan,           min=-6.014090061187744, max=-6.014090061187744\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 42, TRAIN LOSS: 0.47932176275253296\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-6.041862487792969, std=nan,           min=-6.041862487792969, max=-6.041862487792969\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 43, TRAIN LOSS: 0.4742074795913696\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-6.065409183502197, std=nan,           min=-6.065409183502197, max=-6.065409183502197\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 44, TRAIN LOSS: 0.46897499839782714\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-6.088472366333008, std=nan,           min=-6.088472366333008, max=-6.088472366333008\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 45, TRAIN LOSS: 0.4642595296573639\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : alpha : mean=-6.112029075622559, std=nan,           min=-6.112029075622559, max=-6.112029075622559\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 46, TRAIN LOSS: 0.4593181456756592\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-6.13496732711792, std=nan,           min=-6.13496732711792, max=-6.13496732711792\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 47, TRAIN LOSS: 0.4550270121192932\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : alpha : mean=-6.159541606903076, std=nan,           min=-6.159541606903076, max=-6.159541606903076\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 48, TRAIN LOSS: 0.45012630823135374\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-6.181315898895264, std=nan,           min=-6.181315898895264, max=-6.181315898895264\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 49, TRAIN LOSS: 0.4456824262428284\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : alpha : mean=-6.204270362854004, std=nan,           min=-6.204270362854004, max=-6.204270362854004\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 50, TRAIN LOSS: 0.4410446963882446\n",
            "TEST ACCURACY: 0.78125\n"
          ]
        }
      ],
      "source": [
        "#SGDExp-SGD algorithm, meaning hyperoptimization where the learning rate parameter goes through an exp.\n",
        "\n",
        "#model_exp = MNIST_FullyConnected(28 * 28, 128, 16, 16, 10).to(DEVICE)\n",
        "model_exp = CIFAR10_CNN().to(DEVICE)\n",
        "\n",
        "#Create the optimizer\n",
        "optim_exp = SGDExp(alpha=-2.0, exp=True, optimizer=gdtuo.SGD(0.01))\n",
        "mw_exp = gdtuo.ModuleWrapper(model_exp, optimizer=optim_exp)\n",
        "mw_exp.initialize()\n",
        "\n",
        "train_loss, test_acc, test_loss = train(mw_exp, record_data=True)\n",
        "save_training_data(train_loss, test_acc, test_loss, \"SGDExp-SGD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Gmx4DOQrfV",
        "outputId": "3caac4ae-1285-4b30-bfc6-7cbdf119331e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rates : alpha : mean=0.1353352814912796, std=nan,           min=0.1353352814912796, max=0.1353352814912796\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1, TRAIN LOSS: 1.631498437576294\n",
            "TEST ACCURACY: 0.5859375\n",
            "Learning rates : alpha : mean=0.07293841987848282, std=nan,           min=0.07293841987848282, max=0.07293841987848282\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 2, TRAIN LOSS: 1.233410507659912\n",
            "TEST ACCURACY: 0.640625\n",
            "Learning rates : alpha : mean=0.02075101248919964, std=nan,           min=0.02075101248919964, max=0.02075101248919964\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 3, TRAIN LOSS: 1.1151973416900636\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.006120017264038324, std=nan,           min=0.006120017264038324, max=0.006120017264038324\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 4, TRAIN LOSS: 1.0809313529205322\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.000899981358088553, std=nan,           min=0.000899981358088553, max=0.000899981358088553\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 5, TRAIN LOSS: 1.0717874880218505\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=-0.0005620050942525268, std=nan,           min=-0.0005620050942525268, max=-0.0005620050942525268\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 6, TRAIN LOSS: 1.0705839603424072\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=-0.0003293949703220278, std=nan,           min=-0.0003293949703220278, max=-0.0003293949703220278\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 7, TRAIN LOSS: 1.0702707375717162\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=-7.672305218875408e-05, std=nan,           min=-7.672305218875408e-05, max=-7.672305218875408e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 8, TRAIN LOSS: 1.0690276387405395\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0004889344563707709, std=nan,           min=0.0004889344563707709, max=0.0004889344563707709\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 9, TRAIN LOSS: 1.0669825860977173\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.00012855154636781663, std=nan,           min=0.00012855154636781663, max=0.00012855154636781663\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 10, TRAIN LOSS: 1.0662318858337403\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0012985646026208997, std=nan,           min=0.0012985646026208997, max=0.0012985646026208997\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 11, TRAIN LOSS: 1.0635941653442382\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.001376675209030509, std=nan,           min=0.001376675209030509, max=0.001376675209030509\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 12, TRAIN LOSS: 1.0609553133010865\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=-0.00016939634224399924, std=nan,           min=-0.00016939634224399924, max=-0.00016939634224399924\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 13, TRAIN LOSS: 1.0595564176940917\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0005733530269935727, std=nan,           min=0.0005733530269935727, max=0.0005733530269935727\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 14, TRAIN LOSS: 1.0578511122512817\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0001452478754799813, std=nan,           min=0.0001452478754799813, max=0.0001452478754799813\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 15, TRAIN LOSS: 1.0560141788482666\n",
            "TEST ACCURACY: 0.6484375\n",
            "Learning rates : alpha : mean=0.0012231012806296349, std=nan,           min=0.0012231012806296349, max=0.0012231012806296349\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 16, TRAIN LOSS: 1.0526488125991822\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0014713127166032791, std=nan,           min=0.0014713127166032791, max=0.0014713127166032791\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 17, TRAIN LOSS: 1.0501777806091308\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.0012245338875800371, std=nan,           min=0.0012245338875800371, max=0.0012245338875800371\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 18, TRAIN LOSS: 1.0471649491500854\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0012176241725683212, std=nan,           min=0.0012176241725683212, max=0.0012176241725683212\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 19, TRAIN LOSS: 1.0430712398910522\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=-0.0008053635247051716, std=nan,           min=-0.0008053635247051716, max=-0.0008053635247051716\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 20, TRAIN LOSS: 1.0409919817352296\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.0011288938112556934, std=nan,           min=0.0011288938112556934, max=0.0011288938112556934\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 21, TRAIN LOSS: 1.0382109308242797\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0007185211288742721, std=nan,           min=0.0007185211288742721, max=0.0007185211288742721\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 22, TRAIN LOSS: 1.0348559618377686\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.0009305187850259244, std=nan,           min=0.0009305187850259244, max=0.0009305187850259244\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 23, TRAIN LOSS: 1.0333574177360534\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0005840961821377277, std=nan,           min=0.0005840961821377277, max=0.0005840961821377277\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 24, TRAIN LOSS: 1.0304689098358155\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=1.1782874935306609e-05, std=nan,           min=1.1782874935306609e-05, max=1.1782874935306609e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 25, TRAIN LOSS: 1.0284568040275575\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0006186234531924129, std=nan,           min=0.0006186234531924129, max=0.0006186234531924129\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 26, TRAIN LOSS: 1.0279524073410033\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0011097422102466226, std=nan,           min=0.0011097422102466226, max=0.0011097422102466226\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 27, TRAIN LOSS: 1.0261970589065552\n",
            "TEST ACCURACY: 0.65625\n",
            "Learning rates : alpha : mean=0.00010030528937932104, std=nan,           min=0.00010030528937932104, max=0.00010030528937932104\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 28, TRAIN LOSS: 1.0252015143203734\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=-0.0003272088069934398, std=nan,           min=-0.0003272088069934398, max=-0.0003272088069934398\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 29, TRAIN LOSS: 1.0238550157356263\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0008433449547737837, std=nan,           min=0.0008433449547737837, max=0.0008433449547737837\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 30, TRAIN LOSS: 1.0218711478042604\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0004785003839060664, std=nan,           min=0.0004785003839060664, max=0.0004785003839060664\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 31, TRAIN LOSS: 1.0208928911590576\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.00020569803018588573, std=nan,           min=0.00020569803018588573, max=0.00020569803018588573\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 32, TRAIN LOSS: 1.01882265001297\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0012895981781184673, std=nan,           min=0.0012895981781184673, max=0.0012895981781184673\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 33, TRAIN LOSS: 1.0166135711669921\n",
            "TEST ACCURACY: 0.6640625\n",
            "Learning rates : alpha : mean=0.0009644701494835317, std=nan,           min=0.0009644701494835317, max=0.0009644701494835317\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 34, TRAIN LOSS: 1.0145269351196289\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.00016301963478326797, std=nan,           min=0.00016301963478326797, max=0.00016301963478326797\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 35, TRAIN LOSS: 1.013315009498596\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0009854664094746113, std=nan,           min=0.0009854664094746113, max=0.0009854664094746113\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 36, TRAIN LOSS: 1.0117802285957336\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0005210544914007187, std=nan,           min=0.0005210544914007187, max=0.0005210544914007187\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 37, TRAIN LOSS: 1.0103155857086181\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=5.6534445320721716e-05, std=nan,           min=5.6534445320721716e-05, max=5.6534445320721716e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 38, TRAIN LOSS: 1.0094239341545106\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0005422272370196879, std=nan,           min=0.0005422272370196879, max=0.0005422272370196879\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 39, TRAIN LOSS: 1.0081993022155762\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0001704079913906753, std=nan,           min=0.0001704079913906753, max=0.0001704079913906753\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 40, TRAIN LOSS: 1.0061761161994933\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0003514905693009496, std=nan,           min=0.0003514905693009496, max=0.0003514905693009496\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 41, TRAIN LOSS: 1.0046732522201538\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=-1.5273457393050194e-05, std=nan,           min=-1.5273457393050194e-05, max=-1.5273457393050194e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 42, TRAIN LOSS: 1.0027226090240478\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=-7.661172276129946e-05, std=nan,           min=-7.661172276129946e-05, max=-7.661172276129946e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 43, TRAIN LOSS: 1.0018475485038758\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=0.0009743171976879239, std=nan,           min=0.0009743171976879239, max=0.0009743171976879239\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 44, TRAIN LOSS: 0.9988790263366699\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : alpha : mean=0.0006364767905324697, std=nan,           min=0.0006364767905324697, max=0.0006364767905324697\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 45, TRAIN LOSS: 0.9965690731811524\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=-9.859685087576509e-05, std=nan,           min=-9.859685087576509e-05, max=-9.859685087576509e-05\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 46, TRAIN LOSS: 0.9950332931137085\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.0009310729801654816, std=nan,           min=0.0009310729801654816, max=0.0009310729801654816\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 47, TRAIN LOSS: 0.9930375722885132\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : alpha : mean=0.0004122058453503996, std=nan,           min=0.0004122058453503996, max=0.0004122058453503996\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 48, TRAIN LOSS: 0.9910410437011719\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : alpha : mean=0.0003749256138689816, std=nan,           min=0.0003749256138689816, max=0.0003749256138689816\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 49, TRAIN LOSS: 0.9893686863327026\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : alpha : mean=0.00062486034585163, std=nan,           min=0.00062486034585163, max=0.00062486034585163\n",
            "Learning rates : mu : mean=0.0, std=nan,           min=0.0, max=0.0\n",
            "EPOCH: 50, TRAIN LOSS: 0.9874270495796204\n",
            "TEST ACCURACY: 0.6796875\n"
          ]
        }
      ],
      "source": [
        "#SGD-SGD optimizer, as described in Chandra et al's paper (https://arxiv.org/abs/1909.13371)\n",
        "\n",
        "#model = MNIST_FullyConnected(28 * 28, 128, 16, 16, 10).to(DEVICE)\n",
        "model = CIFAR10_CNN().to(DEVICE)\n",
        "\n",
        "#Create the optimizer\n",
        "#optim = gdtuo.SGD(alpha=0.1, optimizer=gdtuo.NoOpOptimizer())\n",
        "optim = gdtuo.SGD(alpha=math.exp(-2.0), optimizer=gdtuo.SGD(0.0001))\n",
        "mw = gdtuo.ModuleWrapper(model, optimizer=optim)\n",
        "mw.initialize()\n",
        "\n",
        "train_loss, test_acc, test_loss = train(mw, record_data=True)\n",
        "save_training_data(train_loss, test_acc, test_loss, \"SGD-SGD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6LkCCfLIRiq",
        "outputId": "d183a820-47f4-44dc-8366-ee153bf07a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rates : conv1.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0, std=nan,           min=-2.0, max=-2.0\n",
            "EPOCH: 1, TRAIN LOSS: 1.6497179019927979\n",
            "TEST ACCURACY: 0.53125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.071364164352417, std=nan,           min=-2.071364164352417, max=-2.071364164352417\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0616061687469482, std=nan,           min=-2.0616061687469482, max=-2.0616061687469482\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.015169620513916, std=nan,           min=-2.015169620513916, max=-2.015169620513916\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0026700496673584, std=nan,           min=-2.0026700496673584, max=-2.0026700496673584\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0194051265716553, std=nan,           min=-2.0194051265716553, max=-2.0194051265716553\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.010854959487915, std=nan,           min=-2.010854959487915, max=-2.010854959487915\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0097475051879883, std=nan,           min=-2.0097475051879883, max=-2.0097475051879883\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000819683074951, std=nan,           min=-2.000819683074951, max=-2.000819683074951\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.010923385620117, std=nan,           min=-2.010923385620117, max=-2.010923385620117\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0053389072418213, std=nan,           min=-2.0053389072418213, max=-2.0053389072418213\n",
            "Learning rates : fc1.weight_alpha : mean=-2.4294021129608154, std=nan,           min=-2.4294021129608154, max=-2.4294021129608154\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0026941299438477, std=nan,           min=-2.0026941299438477, max=-2.0026941299438477\n",
            "Learning rates : fc2.weight_alpha : mean=-2.123392343521118, std=nan,           min=-2.123392343521118, max=-2.123392343521118\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0043070316314697, std=nan,           min=-2.0043070316314697, max=-2.0043070316314697\n",
            "EPOCH: 2, TRAIN LOSS: 1.2463523723220826\n",
            "TEST ACCURACY: 0.6484375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.1497695446014404, std=nan,           min=-2.1497695446014404, max=-2.1497695446014404\n",
            "Learning rates : conv1.bias_alpha : mean=-2.1179513931274414, std=nan,           min=-2.1179513931274414, max=-2.1179513931274414\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0343105792999268, std=nan,           min=-2.0343105792999268, max=-2.0343105792999268\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.006772518157959, std=nan,           min=-2.006772518157959, max=-2.006772518157959\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0482306480407715, std=nan,           min=-2.0482306480407715, max=-2.0482306480407715\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.023224115371704, std=nan,           min=-2.023224115371704, max=-2.023224115371704\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0185768604278564, std=nan,           min=-2.0185768604278564, max=-2.0185768604278564\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.001619577407837, std=nan,           min=-2.001619577407837, max=-2.001619577407837\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0223686695098877, std=nan,           min=-2.0223686695098877, max=-2.0223686695098877\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0084517002105713, std=nan,           min=-2.0084517002105713, max=-2.0084517002105713\n",
            "Learning rates : fc1.weight_alpha : mean=-2.7552309036254883, std=nan,           min=-2.7552309036254883, max=-2.7552309036254883\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0051047801971436, std=nan,           min=-2.0051047801971436, max=-2.0051047801971436\n",
            "Learning rates : fc2.weight_alpha : mean=-2.206949472427368, std=nan,           min=-2.206949472427368, max=-2.206949472427368\n",
            "Learning rates : fc2.bias_alpha : mean=-2.007401466369629, std=nan,           min=-2.007401466369629, max=-2.007401466369629\n",
            "EPOCH: 3, TRAIN LOSS: 1.0791830461502074\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.221527099609375, std=nan,           min=-2.221527099609375, max=-2.221527099609375\n",
            "Learning rates : conv1.bias_alpha : mean=-2.163783311843872, std=nan,           min=-2.163783311843872, max=-2.163783311843872\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0589542388916016, std=nan,           min=-2.0589542388916016, max=-2.0589542388916016\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0121068954467773, std=nan,           min=-2.0121068954467773, max=-2.0121068954467773\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0893092155456543, std=nan,           min=-2.0893092155456543, max=-2.0893092155456543\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.033285140991211, std=nan,           min=-2.033285140991211, max=-2.033285140991211\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.028667688369751, std=nan,           min=-2.028667688369751, max=-2.028667688369751\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.002344846725464, std=nan,           min=-2.002344846725464, max=-2.002344846725464\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0370516777038574, std=nan,           min=-2.0370516777038574, max=-2.0370516777038574\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0107293128967285, std=nan,           min=-2.0107293128967285, max=-2.0107293128967285\n",
            "Learning rates : fc1.weight_alpha : mean=-3.043341875076294, std=nan,           min=-3.043341875076294, max=-3.043341875076294\n",
            "Learning rates : fc1.bias_alpha : mean=-2.007216691970825, std=nan,           min=-2.007216691970825, max=-2.007216691970825\n",
            "Learning rates : fc2.weight_alpha : mean=-2.276925802230835, std=nan,           min=-2.276925802230835, max=-2.276925802230835\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0102035999298096, std=nan,           min=-2.0102035999298096, max=-2.0102035999298096\n",
            "EPOCH: 4, TRAIN LOSS: 0.9534866893386841\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.2845327854156494, std=nan,           min=-2.2845327854156494, max=-2.2845327854156494\n",
            "Learning rates : conv1.bias_alpha : mean=-2.2018702030181885, std=nan,           min=-2.2018702030181885, max=-2.2018702030181885\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.087980031967163, std=nan,           min=-2.087980031967163, max=-2.087980031967163\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0179696083068848, std=nan,           min=-2.0179696083068848, max=-2.0179696083068848\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.14357852935791, std=nan,           min=-2.14357852935791, max=-2.14357852935791\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0424675941467285, std=nan,           min=-2.0424675941467285, max=-2.0424675941467285\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0411689281463623, std=nan,           min=-2.0411689281463623, max=-2.0411689281463623\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.002997398376465, std=nan,           min=-2.002997398376465, max=-2.002997398376465\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0567784309387207, std=nan,           min=-2.0567784309387207, max=-2.0567784309387207\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.012714147567749, std=nan,           min=-2.012714147567749, max=-2.012714147567749\n",
            "Learning rates : fc1.weight_alpha : mean=-3.2786941528320312, std=nan,           min=-3.2786941528320312, max=-3.2786941528320312\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0088372230529785, std=nan,           min=-2.0088372230529785, max=-2.0088372230529785\n",
            "Learning rates : fc2.weight_alpha : mean=-2.334764003753662, std=nan,           min=-2.334764003753662, max=-2.334764003753662\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0124759674072266, std=nan,           min=-2.0124759674072266, max=-2.0124759674072266\n",
            "EPOCH: 5, TRAIN LOSS: 0.8645526161193847\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.341763734817505, std=nan,           min=-2.341763734817505, max=-2.341763734817505\n",
            "Learning rates : conv1.bias_alpha : mean=-2.2370095252990723, std=nan,           min=-2.2370095252990723, max=-2.2370095252990723\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.1190197467803955, std=nan,           min=-2.1190197467803955, max=-2.1190197467803955\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0233876705169678, std=nan,           min=-2.0233876705169678, max=-2.0233876705169678\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.2069687843322754, std=nan,           min=-2.2069687843322754, max=-2.2069687843322754\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0512022972106934, std=nan,           min=-2.0512022972106934, max=-2.0512022972106934\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0563223361968994, std=nan,           min=-2.0563223361968994, max=-2.0563223361968994\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0036420822143555, std=nan,           min=-2.0036420822143555, max=-2.0036420822143555\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0826385021209717, std=nan,           min=-2.0826385021209717, max=-2.0826385021209717\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.014633893966675, std=nan,           min=-2.014633893966675, max=-2.014633893966675\n",
            "Learning rates : fc1.weight_alpha : mean=-3.4970269203186035, std=nan,           min=-3.4970269203186035, max=-3.4970269203186035\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0102837085723877, std=nan,           min=-2.0102837085723877, max=-2.0102837085723877\n",
            "Learning rates : fc2.weight_alpha : mean=-2.3914990425109863, std=nan,           min=-2.3914990425109863, max=-2.3914990425109863\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0145647525787354, std=nan,           min=-2.0145647525787354, max=-2.0145647525787354\n",
            "EPOCH: 6, TRAIN LOSS: 0.7890697605323792\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.3906195163726807, std=nan,           min=-2.3906195163726807, max=-2.3906195163726807\n",
            "Learning rates : conv1.bias_alpha : mean=-2.2679808139801025, std=nan,           min=-2.2679808139801025, max=-2.2679808139801025\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.150163173675537, std=nan,           min=-2.150163173675537, max=-2.150163173675537\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0282540321350098, std=nan,           min=-2.0282540321350098, max=-2.0282540321350098\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.2739763259887695, std=nan,           min=-2.2739763259887695, max=-2.2739763259887695\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0590178966522217, std=nan,           min=-2.0590178966522217, max=-2.0590178966522217\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0730855464935303, std=nan,           min=-2.0730855464935303, max=-2.0730855464935303\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0042130947113037, std=nan,           min=-2.0042130947113037, max=-2.0042130947113037\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.1132240295410156, std=nan,           min=-2.1132240295410156, max=-2.1132240295410156\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0162549018859863, std=nan,           min=-2.0162549018859863, max=-2.0162549018859863\n",
            "Learning rates : fc1.weight_alpha : mean=-3.682529926300049, std=nan,           min=-3.682529926300049, max=-3.682529926300049\n",
            "Learning rates : fc1.bias_alpha : mean=-2.011472225189209, std=nan,           min=-2.011472225189209, max=-2.011472225189209\n",
            "Learning rates : fc2.weight_alpha : mean=-2.4376697540283203, std=nan,           min=-2.4376697540283203, max=-2.4376697540283203\n",
            "Learning rates : fc2.bias_alpha : mean=-2.016244888305664, std=nan,           min=-2.016244888305664, max=-2.016244888305664\n",
            "EPOCH: 7, TRAIN LOSS: 0.725289403591156\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.429535150527954, std=nan,           min=-2.429535150527954, max=-2.429535150527954\n",
            "Learning rates : conv1.bias_alpha : mean=-2.291511297225952, std=nan,           min=-2.291511297225952, max=-2.291511297225952\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.1774628162384033, std=nan,           min=-2.1774628162384033, max=-2.1774628162384033\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.03197979927063, std=nan,           min=-2.03197979927063, max=-2.03197979927063\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.3294646739959717, std=nan,           min=-2.3294646739959717, max=-2.3294646739959717\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.064814567565918, std=nan,           min=-2.064814567565918, max=-2.064814567565918\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.090667724609375, std=nan,           min=-2.090667724609375, max=-2.090667724609375\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0047085285186768, std=nan,           min=-2.0047085285186768, max=-2.0047085285186768\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.1423819065093994, std=nan,           min=-2.1423819065093994, max=-2.1423819065093994\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0175180435180664, std=nan,           min=-2.0175180435180664, max=-2.0175180435180664\n",
            "Learning rates : fc1.weight_alpha : mean=-3.836078405380249, std=nan,           min=-3.836078405380249, max=-3.836078405380249\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0124218463897705, std=nan,           min=-2.0124218463897705, max=-2.0124218463897705\n",
            "Learning rates : fc2.weight_alpha : mean=-2.477154493331909, std=nan,           min=-2.477154493331909, max=-2.477154493331909\n",
            "Learning rates : fc2.bias_alpha : mean=-2.017622470855713, std=nan,           min=-2.017622470855713, max=-2.017622470855713\n",
            "EPOCH: 8, TRAIN LOSS: 0.6750333486366272\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.462327241897583, std=nan,           min=-2.462327241897583, max=-2.462327241897583\n",
            "Learning rates : conv1.bias_alpha : mean=-2.3130128383636475, std=nan,           min=-2.3130128383636475, max=-2.3130128383636475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.2057652473449707, std=nan,           min=-2.2057652473449707, max=-2.2057652473449707\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.035701274871826, std=nan,           min=-2.035701274871826, max=-2.035701274871826\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.385131359100342, std=nan,           min=-2.385131359100342, max=-2.385131359100342\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0702507495880127, std=nan,           min=-2.0702507495880127, max=-2.0702507495880127\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.109609842300415, std=nan,           min=-2.109609842300415, max=-2.109609842300415\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0051920413970947, std=nan,           min=-2.0051920413970947, max=-2.0051920413970947\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.172534942626953, std=nan,           min=-2.172534942626953, max=-2.172534942626953\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.018588066101074, std=nan,           min=-2.018588066101074, max=-2.018588066101074\n",
            "Learning rates : fc1.weight_alpha : mean=-3.9792137145996094, std=nan,           min=-3.9792137145996094, max=-3.9792137145996094\n",
            "Learning rates : fc1.bias_alpha : mean=-2.013272285461426, std=nan,           min=-2.013272285461426, max=-2.013272285461426\n",
            "Learning rates : fc2.weight_alpha : mean=-2.515993118286133, std=nan,           min=-2.515993118286133, max=-2.515993118286133\n",
            "Learning rates : fc2.bias_alpha : mean=-2.018927812576294, std=nan,           min=-2.018927812576294, max=-2.018927812576294\n",
            "EPOCH: 9, TRAIN LOSS: 0.6253148007583618\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.4939963817596436, std=nan,           min=-2.4939963817596436, max=-2.4939963817596436\n",
            "Learning rates : conv1.bias_alpha : mean=-2.330967426300049, std=nan,           min=-2.330967426300049, max=-2.330967426300049\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.2302095890045166, std=nan,           min=-2.2302095890045166, max=-2.2302095890045166\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0388169288635254, std=nan,           min=-2.0388169288635254, max=-2.0388169288635254\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.431962490081787, std=nan,           min=-2.431962490081787, max=-2.431962490081787\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.07425856590271, std=nan,           min=-2.07425856590271, max=-2.07425856590271\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.1286590099334717, std=nan,           min=-2.1286590099334717, max=-2.1286590099334717\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.005626916885376, std=nan,           min=-2.005626916885376, max=-2.005626916885376\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.20295786857605, std=nan,           min=-2.20295786857605, max=-2.20295786857605\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0194931030273438, std=nan,           min=-2.0194931030273438, max=-2.0194931030273438\n",
            "Learning rates : fc1.weight_alpha : mean=-4.108441352844238, std=nan,           min=-4.108441352844238, max=-4.108441352844238\n",
            "Learning rates : fc1.bias_alpha : mean=-2.014031171798706, std=nan,           min=-2.014031171798706, max=-2.014031171798706\n",
            "Learning rates : fc2.weight_alpha : mean=-2.5503697395324707, std=nan,           min=-2.5503697395324707, max=-2.5503697395324707\n",
            "Learning rates : fc2.bias_alpha : mean=-2.020071506500244, std=nan,           min=-2.020071506500244, max=-2.020071506500244\n",
            "EPOCH: 10, TRAIN LOSS: 0.5814503172111511\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.518080472946167, std=nan,           min=-2.518080472946167, max=-2.518080472946167\n",
            "Learning rates : conv1.bias_alpha : mean=-2.3467180728912354, std=nan,           min=-2.3467180728912354, max=-2.3467180728912354\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.25373911857605, std=nan,           min=-2.25373911857605, max=-2.25373911857605\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0415780544281006, std=nan,           min=-2.0415780544281006, max=-2.0415780544281006\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.477266550064087, std=nan,           min=-2.477266550064087, max=-2.477266550064087\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.077894687652588, std=nan,           min=-2.077894687652588, max=-2.077894687652588\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.149068593978882, std=nan,           min=-2.149068593978882, max=-2.149068593978882\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0060150623321533, std=nan,           min=-2.0060150623321533, max=-2.0060150623321533\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.2317817211151123, std=nan,           min=-2.2317817211151123, max=-2.2317817211151123\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0202717781066895, std=nan,           min=-2.0202717781066895, max=-2.0202717781066895\n",
            "Learning rates : fc1.weight_alpha : mean=-4.225148677825928, std=nan,           min=-4.225148677825928, max=-4.225148677825928\n",
            "Learning rates : fc1.bias_alpha : mean=-2.014702558517456, std=nan,           min=-2.014702558517456, max=-2.014702558517456\n",
            "Learning rates : fc2.weight_alpha : mean=-2.5814735889434814, std=nan,           min=-2.5814735889434814, max=-2.5814735889434814\n",
            "Learning rates : fc2.bias_alpha : mean=-2.021054744720459, std=nan,           min=-2.021054744720459, max=-2.021054744720459\n",
            "EPOCH: 11, TRAIN LOSS: 0.5414932168960571\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.541943311691284, std=nan,           min=-2.541943311691284, max=-2.541943311691284\n",
            "Learning rates : conv1.bias_alpha : mean=-2.3613460063934326, std=nan,           min=-2.3613460063934326, max=-2.3613460063934326\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.276174783706665, std=nan,           min=-2.276174783706665, max=-2.276174783706665\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.044329881668091, std=nan,           min=-2.044329881668091, max=-2.044329881668091\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.5225841999053955, std=nan,           min=-2.5225841999053955, max=-2.5225841999053955\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0813095569610596, std=nan,           min=-2.0813095569610596, max=-2.0813095569610596\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.1688177585601807, std=nan,           min=-2.1688177585601807, max=-2.1688177585601807\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.006364583969116, std=nan,           min=-2.006364583969116, max=-2.006364583969116\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.2606208324432373, std=nan,           min=-2.2606208324432373, max=-2.2606208324432373\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0209569931030273, std=nan,           min=-2.0209569931030273, max=-2.0209569931030273\n",
            "Learning rates : fc1.weight_alpha : mean=-4.337282657623291, std=nan,           min=-4.337282657623291, max=-4.337282657623291\n",
            "Learning rates : fc1.bias_alpha : mean=-2.015364408493042, std=nan,           min=-2.015364408493042, max=-2.015364408493042\n",
            "Learning rates : fc2.weight_alpha : mean=-2.6125879287719727, std=nan,           min=-2.6125879287719727, max=-2.6125879287719727\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0220139026641846, std=nan,           min=-2.0220139026641846, max=-2.0220139026641846\n",
            "EPOCH: 12, TRAIN LOSS: 0.5000402245521546\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.5615665912628174, std=nan,           min=-2.5615665912628174, max=-2.5615665912628174\n",
            "Learning rates : conv1.bias_alpha : mean=-2.3739264011383057, std=nan,           min=-2.3739264011383057, max=-2.3739264011383057\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.296304941177368, std=nan,           min=-2.296304941177368, max=-2.296304941177368\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0468647480010986, std=nan,           min=-2.0468647480010986, max=-2.0468647480010986\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.5612740516662598, std=nan,           min=-2.5612740516662598, max=-2.5612740516662598\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0839645862579346, std=nan,           min=-2.0839645862579346, max=-2.0839645862579346\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.1879539489746094, std=nan,           min=-2.1879539489746094, max=-2.1879539489746094\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0066792964935303, std=nan,           min=-2.0066792964935303, max=-2.0066792964935303\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.2877330780029297, std=nan,           min=-2.2877330780029297, max=-2.2877330780029297\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0215280055999756, std=nan,           min=-2.0215280055999756, max=-2.0215280055999756\n",
            "Learning rates : fc1.weight_alpha : mean=-4.440027713775635, std=nan,           min=-4.440027713775635, max=-4.440027713775635\n",
            "Learning rates : fc1.bias_alpha : mean=-2.015929698944092, std=nan,           min=-2.015929698944092, max=-2.015929698944092\n",
            "Learning rates : fc2.weight_alpha : mean=-2.64058256149292, std=nan,           min=-2.64058256149292, max=-2.64058256149292\n",
            "Learning rates : fc2.bias_alpha : mean=-2.022815227508545, std=nan,           min=-2.022815227508545, max=-2.022815227508545\n",
            "EPOCH: 13, TRAIN LOSS: 0.4682670225906372\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.5831100940704346, std=nan,           min=-2.5831100940704346, max=-2.5831100940704346\n",
            "Learning rates : conv1.bias_alpha : mean=-2.3867859840393066, std=nan,           min=-2.3867859840393066, max=-2.3867859840393066\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.3190829753875732, std=nan,           min=-2.3190829753875732, max=-2.3190829753875732\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.049525022506714, std=nan,           min=-2.049525022506714, max=-2.049525022506714\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.602341413497925, std=nan,           min=-2.602341413497925, max=-2.602341413497925\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.086517333984375, std=nan,           min=-2.086517333984375, max=-2.086517333984375\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.208014965057373, std=nan,           min=-2.208014965057373, max=-2.208014965057373\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0069682598114014, std=nan,           min=-2.0069682598114014, max=-2.0069682598114014\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.316732406616211, std=nan,           min=-2.316732406616211, max=-2.316732406616211\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0220606327056885, std=nan,           min=-2.0220606327056885, max=-2.0220606327056885\n",
            "Learning rates : fc1.weight_alpha : mean=-4.544054985046387, std=nan,           min=-4.544054985046387, max=-4.544054985046387\n",
            "Learning rates : fc1.bias_alpha : mean=-2.016510486602783, std=nan,           min=-2.016510486602783, max=-2.016510486602783\n",
            "Learning rates : fc2.weight_alpha : mean=-2.6680123805999756, std=nan,           min=-2.6680123805999756, max=-2.6680123805999756\n",
            "Learning rates : fc2.bias_alpha : mean=-2.023585796356201, std=nan,           min=-2.023585796356201, max=-2.023585796356201\n",
            "EPOCH: 14, TRAIN LOSS: 0.4304562056541443\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.60258150100708, std=nan,           min=-2.60258150100708, max=-2.60258150100708\n",
            "Learning rates : conv1.bias_alpha : mean=-2.397834300994873, std=nan,           min=-2.397834300994873, max=-2.397834300994873\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.3387629985809326, std=nan,           min=-2.3387629985809326, max=-2.3387629985809326\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.051514148712158, std=nan,           min=-2.051514148712158, max=-2.051514148712158\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.639530658721924, std=nan,           min=-2.639530658721924, max=-2.639530658721924\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.08866286277771, std=nan,           min=-2.08866286277771, max=-2.08866286277771\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.225649356842041, std=nan,           min=-2.225649356842041, max=-2.225649356842041\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0071868896484375, std=nan,           min=-2.0071868896484375, max=-2.0071868896484375\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.342866897583008, std=nan,           min=-2.342866897583008, max=-2.342866897583008\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0224661827087402, std=nan,           min=-2.0224661827087402, max=-2.0224661827087402\n",
            "Learning rates : fc1.weight_alpha : mean=-4.634632587432861, std=nan,           min=-4.634632587432861, max=-4.634632587432861\n",
            "Learning rates : fc1.bias_alpha : mean=-2.016998767852783, std=nan,           min=-2.016998767852783, max=-2.016998767852783\n",
            "Learning rates : fc2.weight_alpha : mean=-2.6934092044830322, std=nan,           min=-2.6934092044830322, max=-2.6934092044830322\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0242321491241455, std=nan,           min=-2.0242321491241455, max=-2.0242321491241455\n",
            "EPOCH: 15, TRAIN LOSS: 0.40207243078231814\n",
            "TEST ACCURACY: 0.765625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.6207780838012695, std=nan,           min=-2.6207780838012695, max=-2.6207780838012695\n",
            "Learning rates : conv1.bias_alpha : mean=-2.409721851348877, std=nan,           min=-2.409721851348877, max=-2.409721851348877\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.3594651222229004, std=nan,           min=-2.3594651222229004, max=-2.3594651222229004\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0537352561950684, std=nan,           min=-2.0537352561950684, max=-2.0537352561950684\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.6824653148651123, std=nan,           min=-2.6824653148651123, max=-2.6824653148651123\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0910420417785645, std=nan,           min=-2.0910420417785645, max=-2.0910420417785645\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.2456395626068115, std=nan,           min=-2.2456395626068115, max=-2.2456395626068115\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0074307918548584, std=nan,           min=-2.0074307918548584, max=-2.0074307918548584\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.3740055561065674, std=nan,           min=-2.3740055561065674, max=-2.3740055561065674\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0229332447052, std=nan,           min=-2.0229332447052, max=-2.0229332447052\n",
            "Learning rates : fc1.weight_alpha : mean=-4.731156826019287, std=nan,           min=-4.731156826019287, max=-4.731156826019287\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0175087451934814, std=nan,           min=-2.0175087451934814, max=-2.0175087451934814\n",
            "Learning rates : fc2.weight_alpha : mean=-2.7202653884887695, std=nan,           min=-2.7202653884887695, max=-2.7202653884887695\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0248923301696777, std=nan,           min=-2.0248923301696777, max=-2.0248923301696777\n",
            "EPOCH: 16, TRAIN LOSS: 0.3686302358341217\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.636669158935547, std=nan,           min=-2.636669158935547, max=-2.636669158935547\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4201319217681885, std=nan,           min=-2.4201319217681885, max=-2.4201319217681885\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.3802316188812256, std=nan,           min=-2.3802316188812256, max=-2.3802316188812256\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.055752754211426, std=nan,           min=-2.055752754211426, max=-2.055752754211426\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.7195887565612793, std=nan,           min=-2.7195887565612793, max=-2.7195887565612793\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0928738117218018, std=nan,           min=-2.0928738117218018, max=-2.0928738117218018\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.262653112411499, std=nan,           min=-2.262653112411499, max=-2.262653112411499\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.007612943649292, std=nan,           min=-2.007612943649292, max=-2.007612943649292\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.400698184967041, std=nan,           min=-2.400698184967041, max=-2.400698184967041\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0232937335968018, std=nan,           min=-2.0232937335968018, max=-2.0232937335968018\n",
            "Learning rates : fc1.weight_alpha : mean=-4.817328453063965, std=nan,           min=-4.817328453063965, max=-4.817328453063965\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0179507732391357, std=nan,           min=-2.0179507732391357, max=-2.0179507732391357\n",
            "Learning rates : fc2.weight_alpha : mean=-2.7439026832580566, std=nan,           min=-2.7439026832580566, max=-2.7439026832580566\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0254392623901367, std=nan,           min=-2.0254392623901367, max=-2.0254392623901367\n",
            "EPOCH: 17, TRAIN LOSS: 0.3396578709793091\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.6520752906799316, std=nan,           min=-2.6520752906799316, max=-2.6520752906799316\n",
            "Learning rates : conv1.bias_alpha : mean=-2.429387331008911, std=nan,           min=-2.429387331008911, max=-2.429387331008911\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.3993985652923584, std=nan,           min=-2.3993985652923584, max=-2.3993985652923584\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0575485229492188, std=nan,           min=-2.0575485229492188, max=-2.0575485229492188\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.7570459842681885, std=nan,           min=-2.7570459842681885, max=-2.7570459842681885\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0945944786071777, std=nan,           min=-2.0945944786071777, max=-2.0945944786071777\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.281165361404419, std=nan,           min=-2.281165361404419, max=-2.281165361404419\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.007807731628418, std=nan,           min=-2.007807731628418, max=-2.007807731628418\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.4304158687591553, std=nan,           min=-2.4304158687591553, max=-2.4304158687591553\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0236594676971436, std=nan,           min=-2.0236594676971436, max=-2.0236594676971436\n",
            "Learning rates : fc1.weight_alpha : mean=-4.906660556793213, std=nan,           min=-4.906660556793213, max=-4.906660556793213\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0184078216552734, std=nan,           min=-2.0184078216552734, max=-2.0184078216552734\n",
            "Learning rates : fc2.weight_alpha : mean=-2.7689383029937744, std=nan,           min=-2.7689383029937744, max=-2.7689383029937744\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0260112285614014, std=nan,           min=-2.0260112285614014, max=-2.0260112285614014\n",
            "EPOCH: 18, TRAIN LOSS: 0.309490161447525\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.666180372238159, std=nan,           min=-2.666180372238159, max=-2.666180372238159\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4386327266693115, std=nan,           min=-2.4386327266693115, max=-2.4386327266693115\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.4196407794952393, std=nan,           min=-2.4196407794952393, max=-2.4196407794952393\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0594406127929688, std=nan,           min=-2.0594406127929688, max=-2.0594406127929688\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.7951927185058594, std=nan,           min=-2.7951927185058594, max=-2.7951927185058594\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0962109565734863, std=nan,           min=-2.0962109565734863, max=-2.0962109565734863\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.2997703552246094, std=nan,           min=-2.2997703552246094, max=-2.2997703552246094\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0079872608184814, std=nan,           min=-2.0079872608184814, max=-2.0079872608184814\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.4575228691101074, std=nan,           min=-2.4575228691101074, max=-2.4575228691101074\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.023952007293701, std=nan,           min=-2.023952007293701, max=-2.023952007293701\n",
            "Learning rates : fc1.weight_alpha : mean=-4.987829685211182, std=nan,           min=-4.987829685211182, max=-4.987829685211182\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0188064575195312, std=nan,           min=-2.0188064575195312, max=-2.0188064575195312\n",
            "Learning rates : fc2.weight_alpha : mean=-2.7919063568115234, std=nan,           min=-2.7919063568115234, max=-2.7919063568115234\n",
            "Learning rates : fc2.bias_alpha : mean=-2.026467800140381, std=nan,           min=-2.026467800140381, max=-2.026467800140381\n",
            "EPOCH: 19, TRAIN LOSS: 0.2805563039493561\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.6794967651367188, std=nan,           min=-2.6794967651367188, max=-2.6794967651367188\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4468061923980713, std=nan,           min=-2.4468061923980713, max=-2.4468061923980713\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.437932014465332, std=nan,           min=-2.437932014465332, max=-2.437932014465332\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0610320568084717, std=nan,           min=-2.0610320568084717, max=-2.0610320568084717\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.8290467262268066, std=nan,           min=-2.8290467262268066, max=-2.8290467262268066\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.097557544708252, std=nan,           min=-2.097557544708252, max=-2.097557544708252\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.316105842590332, std=nan,           min=-2.316105842590332, max=-2.316105842590332\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.008124351501465, std=nan,           min=-2.008124351501465, max=-2.008124351501465\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.484027862548828, std=nan,           min=-2.484027862548828, max=-2.484027862548828\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0242040157318115, std=nan,           min=-2.0242040157318115, max=-2.0242040157318115\n",
            "Learning rates : fc1.weight_alpha : mean=-5.061492919921875, std=nan,           min=-5.061492919921875, max=-5.061492919921875\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0191617012023926, std=nan,           min=-2.0191617012023926, max=-2.0191617012023926\n",
            "Learning rates : fc2.weight_alpha : mean=-2.8135342597961426, std=nan,           min=-2.8135342597961426, max=-2.8135342597961426\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0268795490264893, std=nan,           min=-2.0268795490264893, max=-2.0268795490264893\n",
            "EPOCH: 20, TRAIN LOSS: 0.25259824903011324\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.6927602291107178, std=nan,           min=-2.6927602291107178, max=-2.6927602291107178\n",
            "Learning rates : conv1.bias_alpha : mean=-2.454669952392578, std=nan,           min=-2.454669952392578, max=-2.454669952392578\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.455784559249878, std=nan,           min=-2.455784559249878, max=-2.455784559249878\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.062509775161743, std=nan,           min=-2.062509775161743, max=-2.062509775161743\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.8599588871002197, std=nan,           min=-2.8599588871002197, max=-2.8599588871002197\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0986454486846924, std=nan,           min=-2.0986454486846924, max=-2.0986454486846924\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.332911729812622, std=nan,           min=-2.332911729812622, max=-2.332911729812622\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0082578659057617, std=nan,           min=-2.0082578659057617, max=-2.0082578659057617\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.5094525814056396, std=nan,           min=-2.5094525814056396, max=-2.5094525814056396\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0244202613830566, std=nan,           min=-2.0244202613830566, max=-2.0244202613830566\n",
            "Learning rates : fc1.weight_alpha : mean=-5.136692523956299, std=nan,           min=-5.136692523956299, max=-5.136692523956299\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0195059776306152, std=nan,           min=-2.0195059776306152, max=-2.0195059776306152\n",
            "Learning rates : fc2.weight_alpha : mean=-2.8357291221618652, std=nan,           min=-2.8357291221618652, max=-2.8357291221618652\n",
            "Learning rates : fc2.bias_alpha : mean=-2.027270555496216, std=nan,           min=-2.027270555496216, max=-2.027270555496216\n",
            "EPOCH: 21, TRAIN LOSS: 0.23059811961174012\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7058420181274414, std=nan,           min=-2.7058420181274414, max=-2.7058420181274414\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4634339809417725, std=nan,           min=-2.4634339809417725, max=-2.4634339809417725\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.47441029548645, std=nan,           min=-2.47441029548645, max=-2.47441029548645\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0641114711761475, std=nan,           min=-2.0641114711761475, max=-2.0641114711761475\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.8960373401641846, std=nan,           min=-2.8960373401641846, max=-2.8960373401641846\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0998823642730713, std=nan,           min=-2.0998823642730713, max=-2.0998823642730713\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.352238655090332, std=nan,           min=-2.352238655090332, max=-2.352238655090332\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.008399724960327, std=nan,           min=-2.008399724960327, max=-2.008399724960327\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.5389328002929688, std=nan,           min=-2.5389328002929688, max=-2.5389328002929688\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0246455669403076, std=nan,           min=-2.0246455669403076, max=-2.0246455669403076\n",
            "Learning rates : fc1.weight_alpha : mean=-5.213780403137207, std=nan,           min=-5.213780403137207, max=-5.213780403137207\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0198400020599365, std=nan,           min=-2.0198400020599365, max=-2.0198400020599365\n",
            "Learning rates : fc2.weight_alpha : mean=-2.858474016189575, std=nan,           min=-2.858474016189575, max=-2.858474016189575\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0276284217834473, std=nan,           min=-2.0276284217834473, max=-2.0276284217834473\n",
            "EPOCH: 22, TRAIN LOSS: 0.20496746942043303\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7181663513183594, std=nan,           min=-2.7181663513183594, max=-2.7181663513183594\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4700398445129395, std=nan,           min=-2.4700398445129395, max=-2.4700398445129395\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.49149227142334, std=nan,           min=-2.49149227142334, max=-2.49149227142334\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.065441846847534, std=nan,           min=-2.065441846847534, max=-2.065441846847534\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.9249398708343506, std=nan,           min=-2.9249398708343506, max=-2.9249398708343506\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.10078501701355, std=nan,           min=-2.10078501701355, max=-2.10078501701355\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.3679487705230713, std=nan,           min=-2.3679487705230713, max=-2.3679487705230713\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.008509397506714, std=nan,           min=-2.008509397506714, max=-2.008509397506714\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.5626542568206787, std=nan,           min=-2.5626542568206787, max=-2.5626542568206787\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0248162746429443, std=nan,           min=-2.0248162746429443, max=-2.0248162746429443\n",
            "Learning rates : fc1.weight_alpha : mean=-5.282448768615723, std=nan,           min=-5.282448768615723, max=-5.282448768615723\n",
            "Learning rates : fc1.bias_alpha : mean=-2.020141839981079, std=nan,           min=-2.020141839981079, max=-2.020141839981079\n",
            "Learning rates : fc2.weight_alpha : mean=-2.879337787628174, std=nan,           min=-2.879337787628174, max=-2.879337787628174\n",
            "Learning rates : fc2.bias_alpha : mean=-2.027951717376709, std=nan,           min=-2.027951717376709, max=-2.027951717376709\n",
            "EPOCH: 23, TRAIN LOSS: 0.18052048716545105\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.72782039642334, std=nan,           min=-2.72782039642334, max=-2.72782039642334\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4759299755096436, std=nan,           min=-2.4759299755096436, max=-2.4759299755096436\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.507035255432129, std=nan,           min=-2.507035255432129, max=-2.507035255432129\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0666677951812744, std=nan,           min=-2.0666677951812744, max=-2.0666677951812744\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.951371431350708, std=nan,           min=-2.951371431350708, max=-2.951371431350708\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1015677452087402, std=nan,           min=-2.1015677452087402, max=-2.1015677452087402\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.3830668926239014, std=nan,           min=-2.3830668926239014, max=-2.3830668926239014\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0086052417755127, std=nan,           min=-2.0086052417755127, max=-2.0086052417755127\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.585308313369751, std=nan,           min=-2.585308313369751, max=-2.585308313369751\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0249669551849365, std=nan,           min=-2.0249669551849365, max=-2.0249669551849365\n",
            "Learning rates : fc1.weight_alpha : mean=-5.344454288482666, std=nan,           min=-5.344454288482666, max=-5.344454288482666\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0203983783721924, std=nan,           min=-2.0203983783721924, max=-2.0203983783721924\n",
            "Learning rates : fc2.weight_alpha : mean=-2.8975768089294434, std=nan,           min=-2.8975768089294434, max=-2.8975768089294434\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0282161235809326, std=nan,           min=-2.0282161235809326, max=-2.0282161235809326\n",
            "EPOCH: 24, TRAIN LOSS: 0.16086655332565308\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7375988960266113, std=nan,           min=-2.7375988960266113, max=-2.7375988960266113\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4822494983673096, std=nan,           min=-2.4822494983673096, max=-2.4822494983673096\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.523023843765259, std=nan,           min=-2.523023843765259, max=-2.523023843765259\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0678577423095703, std=nan,           min=-2.0678577423095703, max=-2.0678577423095703\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.9806089401245117, std=nan,           min=-2.9806089401245117, max=-2.9806089401245117\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1023778915405273, std=nan,           min=-2.1023778915405273, max=-2.1023778915405273\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.3983845710754395, std=nan,           min=-2.3983845710754395, max=-2.3983845710754395\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0086886882781982, std=nan,           min=-2.0086886882781982, max=-2.0086886882781982\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.6104869842529297, std=nan,           min=-2.6104869842529297, max=-2.6104869842529297\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0251152515411377, std=nan,           min=-2.0251152515411377, max=-2.0251152515411377\n",
            "Learning rates : fc1.weight_alpha : mean=-5.405813217163086, std=nan,           min=-5.405813217163086, max=-5.405813217163086\n",
            "Learning rates : fc1.bias_alpha : mean=-2.020641565322876, std=nan,           min=-2.020641565322876, max=-2.020641565322876\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9155726432800293, std=nan,           min=-2.9155726432800293, max=-2.9155726432800293\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0284411907196045, std=nan,           min=-2.0284411907196045, max=-2.0284411907196045\n",
            "EPOCH: 25, TRAIN LOSS: 0.14189890076637268\n",
            "TEST ACCURACY: 0.7421875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7461960315704346, std=nan,           min=-2.7461960315704346, max=-2.7461960315704346\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4877495765686035, std=nan,           min=-2.4877495765686035, max=-2.4877495765686035\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.536691188812256, std=nan,           min=-2.536691188812256, max=-2.536691188812256\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.068833589553833, std=nan,           min=-2.068833589553833, max=-2.068833589553833\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.0065760612487793, std=nan,           min=-3.0065760612487793, max=-3.0065760612487793\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1030702590942383, std=nan,           min=-2.1030702590942383, max=-2.1030702590942383\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.413416862487793, std=nan,           min=-2.413416862487793, max=-2.413416862487793\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0087645053863525, std=nan,           min=-2.0087645053863525, max=-2.0087645053863525\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.6342275142669678, std=nan,           min=-2.6342275142669678, max=-2.6342275142669678\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0252432823181152, std=nan,           min=-2.0252432823181152, max=-2.0252432823181152\n",
            "Learning rates : fc1.weight_alpha : mean=-5.460838317871094, std=nan,           min=-5.460838317871094, max=-5.460838317871094\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0208442211151123, std=nan,           min=-2.0208442211151123, max=-2.0208442211151123\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9313313961029053, std=nan,           min=-2.9313313961029053, max=-2.9313313961029053\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0286309719085693, std=nan,           min=-2.0286309719085693, max=-2.0286309719085693\n",
            "EPOCH: 26, TRAIN LOSS: 0.12517837778568267\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.755528688430786, std=nan,           min=-2.755528688430786, max=-2.755528688430786\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4933652877807617, std=nan,           min=-2.4933652877807617, max=-2.4933652877807617\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.55183482170105, std=nan,           min=-2.55183482170105, max=-2.55183482170105\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0698952674865723, std=nan,           min=-2.0698952674865723, max=-2.0698952674865723\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.034241199493408, std=nan,           min=-3.034241199493408, max=-3.034241199493408\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1037492752075195, std=nan,           min=-2.1037492752075195, max=-2.1037492752075195\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.428123712539673, std=nan,           min=-2.428123712539673, max=-2.428123712539673\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.00883412361145, std=nan,           min=-2.00883412361145, max=-2.00883412361145\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.6569645404815674, std=nan,           min=-2.6569645404815674, max=-2.6569645404815674\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025362730026245, std=nan,           min=-2.025362730026245, max=-2.025362730026245\n",
            "Learning rates : fc1.weight_alpha : mean=-5.5158562660217285, std=nan,           min=-5.5158562660217285, max=-5.5158562660217285\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021042585372925, std=nan,           min=-2.021042585372925, max=-2.021042585372925\n",
            "Learning rates : fc2.weight_alpha : mean=-2.948490619659424, std=nan,           min=-2.948490619659424, max=-2.948490619659424\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0288102626800537, std=nan,           min=-2.0288102626800537, max=-2.0288102626800537\n",
            "EPOCH: 27, TRAIN LOSS: 0.10474244249820709\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.761779308319092, std=nan,           min=-2.761779308319092, max=-2.761779308319092\n",
            "Learning rates : conv1.bias_alpha : mean=-2.4975028038024902, std=nan,           min=-2.4975028038024902, max=-2.4975028038024902\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.5630757808685303, std=nan,           min=-2.5630757808685303, max=-2.5630757808685303\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0706934928894043, std=nan,           min=-2.0706934928894043, max=-2.0706934928894043\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.056133270263672, std=nan,           min=-3.056133270263672, max=-3.056133270263672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1042518615722656, std=nan,           min=-2.1042518615722656, max=-2.1042518615722656\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.439762830734253, std=nan,           min=-2.439762830734253, max=-2.439762830734253\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0088891983032227, std=nan,           min=-2.0088891983032227, max=-2.0088891983032227\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.6773135662078857, std=nan,           min=-2.6773135662078857, max=-2.6773135662078857\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0254628658294678, std=nan,           min=-2.0254628658294678, max=-2.0254628658294678\n",
            "Learning rates : fc1.weight_alpha : mean=-5.565249443054199, std=nan,           min=-5.565249443054199, max=-5.565249443054199\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021216630935669, std=nan,           min=-2.021216630935669, max=-2.021216630935669\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9630839824676514, std=nan,           min=-2.9630839824676514, max=-2.9630839824676514\n",
            "Learning rates : fc2.bias_alpha : mean=-2.028963565826416, std=nan,           min=-2.028963565826416, max=-2.028963565826416\n",
            "EPOCH: 28, TRAIN LOSS: 0.08893128109455109\n",
            "TEST ACCURACY: 0.765625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.76888370513916, std=nan,           min=-2.76888370513916, max=-2.76888370513916\n",
            "Learning rates : conv1.bias_alpha : mean=-2.501357316970825, std=nan,           min=-2.501357316970825, max=-2.501357316970825\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.573925733566284, std=nan,           min=-2.573925733566284, max=-2.573925733566284\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.071354627609253, std=nan,           min=-2.071354627609253, max=-2.071354627609253\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.076418399810791, std=nan,           min=-3.076418399810791, max=-3.076418399810791\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1046595573425293, std=nan,           min=-2.1046595573425293, max=-2.1046595573425293\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.452566385269165, std=nan,           min=-2.452566385269165, max=-2.452566385269165\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0089402198791504, std=nan,           min=-2.0089402198791504, max=-2.0089402198791504\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.6962523460388184, std=nan,           min=-2.6962523460388184, max=-2.6962523460388184\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.02553653717041, std=nan,           min=-2.02553653717041, max=-2.02553653717041\n",
            "Learning rates : fc1.weight_alpha : mean=-5.606304168701172, std=nan,           min=-5.606304168701172, max=-5.606304168701172\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0213475227355957, std=nan,           min=-2.0213475227355957, max=-2.0213475227355957\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9759397506713867, std=nan,           min=-2.9759397506713867, max=-2.9759397506713867\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0290768146514893, std=nan,           min=-2.0290768146514893, max=-2.0290768146514893\n",
            "EPOCH: 29, TRAIN LOSS: 0.07230118982315063\n",
            "TEST ACCURACY: 0.75\n",
            "Learning rates : conv1.weight_alpha : mean=-2.773090124130249, std=nan,           min=-2.773090124130249, max=-2.773090124130249\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5041584968566895, std=nan,           min=-2.5041584968566895, max=-2.5041584968566895\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.581932783126831, std=nan,           min=-2.581932783126831, max=-2.581932783126831\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0718109607696533, std=nan,           min=-2.0718109607696533, max=-2.0718109607696533\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.0910820960998535, std=nan,           min=-3.0910820960998535, max=-3.0910820960998535\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.10493540763855, std=nan,           min=-2.10493540763855, max=-2.10493540763855\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4613828659057617, std=nan,           min=-2.4613828659057617, max=-2.4613828659057617\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0089755058288574, std=nan,           min=-2.0089755058288574, max=-2.0089755058288574\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7092385292053223, std=nan,           min=-2.7092385292053223, max=-2.7092385292053223\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0255839824676514, std=nan,           min=-2.0255839824676514, max=-2.0255839824676514\n",
            "Learning rates : fc1.weight_alpha : mean=-5.635476589202881, std=nan,           min=-5.635476589202881, max=-5.635476589202881\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0214338302612305, std=nan,           min=-2.0214338302612305, max=-2.0214338302612305\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9852986335754395, std=nan,           min=-2.9852986335754395, max=-2.9852986335754395\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029151201248169, std=nan,           min=-2.029151201248169, max=-2.029151201248169\n",
            "EPOCH: 30, TRAIN LOSS: 0.06388569800376892\n",
            "TEST ACCURACY: 0.7890625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7792091369628906, std=nan,           min=-2.7792091369628906, max=-2.7792091369628906\n",
            "Learning rates : conv1.bias_alpha : mean=-2.50762677192688, std=nan,           min=-2.50762677192688, max=-2.50762677192688\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.592264413833618, std=nan,           min=-2.592264413833618, max=-2.592264413833618\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0724048614501953, std=nan,           min=-2.0724048614501953, max=-2.0724048614501953\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1087191104888916, std=nan,           min=-3.1087191104888916, max=-3.1087191104888916\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1052613258361816, std=nan,           min=-2.1052613258361816, max=-2.1052613258361816\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4720475673675537, std=nan,           min=-2.4720475673675537, max=-2.4720475673675537\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.009014368057251, std=nan,           min=-2.009014368057251, max=-2.009014368057251\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.725332498550415, std=nan,           min=-2.725332498550415, max=-2.725332498550415\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0256409645080566, std=nan,           min=-2.0256409645080566, max=-2.0256409645080566\n",
            "Learning rates : fc1.weight_alpha : mean=-5.667275428771973, std=nan,           min=-5.667275428771973, max=-5.667275428771973\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0215251445770264, std=nan,           min=-2.0215251445770264, max=-2.0215251445770264\n",
            "Learning rates : fc2.weight_alpha : mean=-2.9953560829162598, std=nan,           min=-2.9953560829162598, max=-2.9953560829162598\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029226064682007, std=nan,           min=-2.029226064682007, max=-2.029226064682007\n",
            "EPOCH: 31, TRAIN LOSS: 0.050968472858667374\n",
            "TEST ACCURACY: 0.78125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.783470869064331, std=nan,           min=-2.783470869064331, max=-2.783470869064331\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5103952884674072, std=nan,           min=-2.5103952884674072, max=-2.5103952884674072\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.600362777709961, std=nan,           min=-2.600362777709961, max=-2.600362777709961\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.072875499725342, std=nan,           min=-2.072875499725342, max=-2.072875499725342\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.124013900756836, std=nan,           min=-3.124013900756836, max=-3.124013900756836\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1055259704589844, std=nan,           min=-2.1055259704589844, max=-2.1055259704589844\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.481152057647705, std=nan,           min=-2.481152057647705, max=-2.481152057647705\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090417861938477, std=nan,           min=-2.0090417861938477, max=-2.0090417861938477\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7388646602630615, std=nan,           min=-2.7388646602630615, max=-2.7388646602630615\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0256850719451904, std=nan,           min=-2.0256850719451904, max=-2.0256850719451904\n",
            "Learning rates : fc1.weight_alpha : mean=-5.698318958282471, std=nan,           min=-5.698318958282471, max=-5.698318958282471\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0216078758239746, std=nan,           min=-2.0216078758239746, max=-2.0216078758239746\n",
            "Learning rates : fc2.weight_alpha : mean=-3.004199981689453, std=nan,           min=-3.004199981689453, max=-3.004199981689453\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0292856693267822, std=nan,           min=-2.0292856693267822, max=-2.0292856693267822\n",
            "EPOCH: 32, TRAIN LOSS: 0.0342256571495533\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.785266876220703, std=nan,           min=-2.785266876220703, max=-2.785266876220703\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5116024017333984, std=nan,           min=-2.5116024017333984, max=-2.5116024017333984\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.60377836227417, std=nan,           min=-2.60377836227417, max=-2.60377836227417\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0730793476104736, std=nan,           min=-2.0730793476104736, max=-2.0730793476104736\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1295361518859863, std=nan,           min=-3.1295361518859863, max=-3.1295361518859863\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1056175231933594, std=nan,           min=-2.1056175231933594, max=-2.1056175231933594\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.484604597091675, std=nan,           min=-2.484604597091675, max=-2.484604597091675\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.009049892425537, std=nan,           min=-2.009049892425537, max=-2.009049892425537\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.743894577026367, std=nan,           min=-2.743894577026367, max=-2.743894577026367\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025697708129883, std=nan,           min=-2.025697708129883, max=-2.025697708129883\n",
            "Learning rates : fc1.weight_alpha : mean=-5.710146427154541, std=nan,           min=-5.710146427154541, max=-5.710146427154541\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021636724472046, std=nan,           min=-2.021636724472046, max=-2.021636724472046\n",
            "Learning rates : fc2.weight_alpha : mean=-3.00785756111145, std=nan,           min=-3.00785756111145, max=-3.00785756111145\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0293056964874268, std=nan,           min=-2.0293056964874268, max=-2.0293056964874268\n",
            "EPOCH: 33, TRAIN LOSS: 0.02410170789897442\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.786191701889038, std=nan,           min=-2.786191701889038, max=-2.786191701889038\n",
            "Learning rates : conv1.bias_alpha : mean=-2.51218843460083, std=nan,           min=-2.51218843460083, max=-2.51218843460083\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.605560541152954, std=nan,           min=-2.605560541152954, max=-2.605560541152954\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.073176860809326, std=nan,           min=-2.073176860809326, max=-2.073176860809326\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1325106620788574, std=nan,           min=-3.1325106620788574, max=-3.1325106620788574\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1056625843048096, std=nan,           min=-2.1056625843048096, max=-2.1056625843048096\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4865829944610596, std=nan,           min=-2.4865829944610596, max=-2.4865829944610596\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090532302856445, std=nan,           min=-2.0090532302856445, max=-2.0090532302856445\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7469964027404785, std=nan,           min=-2.7469964027404785, max=-2.7469964027404785\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025700330734253, std=nan,           min=-2.025700330734253, max=-2.025700330734253\n",
            "Learning rates : fc1.weight_alpha : mean=-5.7172136306762695, std=nan,           min=-5.7172136306762695, max=-5.7172136306762695\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0216503143310547, std=nan,           min=-2.0216503143310547, max=-2.0216503143310547\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0102944374084473, std=nan,           min=-3.0102944374084473, max=-3.0102944374084473\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029315710067749, std=nan,           min=-2.029315710067749, max=-2.029315710067749\n",
            "EPOCH: 34, TRAIN LOSS: 0.02127211373567581\n",
            "TEST ACCURACY: 0.7734375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7873175144195557, std=nan,           min=-2.7873175144195557, max=-2.7873175144195557\n",
            "Learning rates : conv1.bias_alpha : mean=-2.513079881668091, std=nan,           min=-2.513079881668091, max=-2.513079881668091\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.608853816986084, std=nan,           min=-2.608853816986084, max=-2.608853816986084\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.073324680328369, std=nan,           min=-2.073324680328369, max=-2.073324680328369\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.139566421508789, std=nan,           min=-3.139566421508789, max=-3.139566421508789\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.105745553970337, std=nan,           min=-2.105745553970337, max=-2.105745553970337\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4909512996673584, std=nan,           min=-2.4909512996673584, max=-2.4909512996673584\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.009058713912964, std=nan,           min=-2.009058713912964, max=-2.009058713912964\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7535595893859863, std=nan,           min=-2.7535595893859863, max=-2.7535595893859863\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025709629058838, std=nan,           min=-2.025709629058838, max=-2.025709629058838\n",
            "Learning rates : fc1.weight_alpha : mean=-5.729752540588379, std=nan,           min=-5.729752540588379, max=-5.729752540588379\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0216686725616455, std=nan,           min=-2.0216686725616455, max=-2.0216686725616455\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0161752700805664, std=nan,           min=-3.0161752700805664, max=-3.0161752700805664\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0293290615081787, std=nan,           min=-2.0293290615081787, max=-2.0293290615081787\n",
            "EPOCH: 35, TRAIN LOSS: 0.014109493600726128\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.787883758544922, std=nan,           min=-2.787883758544922, max=-2.787883758544922\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5134212970733643, std=nan,           min=-2.5134212970733643, max=-2.5134212970733643\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.609980344772339, std=nan,           min=-2.609980344772339, max=-2.609980344772339\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0733845233917236, std=nan,           min=-2.0733845233917236, max=-2.0733845233917236\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.141094446182251, std=nan,           min=-3.141094446182251, max=-3.141094446182251\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057651042938232, std=nan,           min=-2.1057651042938232, max=-2.1057651042938232\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4921014308929443, std=nan,           min=-2.4921014308929443, max=-2.4921014308929443\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090596675872803, std=nan,           min=-2.0090596675872803, max=-2.0090596675872803\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.755404233932495, std=nan,           min=-2.755404233932495, max=-2.755404233932495\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0257112979888916, std=nan,           min=-2.0257112979888916, max=-2.0257112979888916\n",
            "Learning rates : fc1.weight_alpha : mean=-5.733463287353516, std=nan,           min=-5.733463287353516, max=-5.733463287353516\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0216734409332275, std=nan,           min=-2.0216734409332275, max=-2.0216734409332275\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017155885696411, std=nan,           min=-3.017155885696411, max=-3.017155885696411\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0293312072753906, std=nan,           min=-2.0293312072753906, max=-2.0293312072753906\n",
            "EPOCH: 36, TRAIN LOSS: 0.009018503491580487\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.78800106048584, std=nan,           min=-2.78800106048584, max=-2.78800106048584\n",
            "Learning rates : conv1.bias_alpha : mean=-2.51351261138916, std=nan,           min=-2.51351261138916, max=-2.51351261138916\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.61035418510437, std=nan,           min=-2.61035418510437, max=-2.61035418510437\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.073401927947998, std=nan,           min=-2.073401927947998, max=-2.073401927947998\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.141713857650757, std=nan,           min=-3.141713857650757, max=-3.141713857650757\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057705879211426, std=nan,           min=-2.1057705879211426, max=-2.1057705879211426\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4925172328948975, std=nan,           min=-2.4925172328948975, max=-2.4925172328948975\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7560572624206543, std=nan,           min=-2.7560572624206543, max=-2.7560572624206543\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712013244629, std=nan,           min=-2.025712013244629, max=-2.025712013244629\n",
            "Learning rates : fc1.weight_alpha : mean=-5.7346062660217285, std=nan,           min=-5.7346062660217285, max=-5.7346062660217285\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674633026123, std=nan,           min=-2.021674633026123, max=-2.021674633026123\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017489433288574, std=nan,           min=-3.017489433288574, max=-3.017489433288574\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 37, TRAIN LOSS: 0.005835839423984289\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880213260650635, std=nan,           min=-2.7880213260650635, max=-2.7880213260650635\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135340690612793, std=nan,           min=-2.5135340690612793, max=-2.5135340690612793\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610408306121826, std=nan,           min=-2.610408306121826, max=-2.610408306121826\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.073403835296631, std=nan,           min=-2.073403835296631, max=-2.073403835296631\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1418168544769287, std=nan,           min=-3.1418168544769287, max=-3.1418168544769287\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.105771064758301, std=nan,           min=-2.105771064758301, max=-2.105771064758301\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.49259352684021, std=nan,           min=-2.49259352684021, max=-2.49259352684021\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7561583518981934, std=nan,           min=-2.7561583518981934, max=-2.7561583518981934\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712013244629, std=nan,           min=-2.025712013244629, max=-2.025712013244629\n",
            "Learning rates : fc1.weight_alpha : mean=-5.734787940979004, std=nan,           min=-5.734787940979004, max=-5.734787940979004\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674633026123, std=nan,           min=-2.021674633026123, max=-2.021674633026123\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017554998397827, std=nan,           min=-3.017554998397827, max=-3.017554998397827\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 38, TRAIN LOSS: 0.004245090062022209\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880494594573975, std=nan,           min=-2.7880494594573975, max=-2.7880494594573975\n",
            "Learning rates : conv1.bias_alpha : mean=-2.513561248779297, std=nan,           min=-2.513561248779297, max=-2.513561248779297\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610503911972046, std=nan,           min=-2.610503911972046, max=-2.610503911972046\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734071731567383, std=nan,           min=-2.0734071731567383, max=-2.0734071731567383\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.141974925994873, std=nan,           min=-3.141974925994873, max=-3.141974925994873\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.492687463760376, std=nan,           min=-2.492687463760376, max=-2.492687463760376\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.756319522857666, std=nan,           min=-2.756319522857666, max=-2.756319522857666\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735036373138428, std=nan,           min=-5.735036373138428, max=-5.735036373138428\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0176258087158203, std=nan,           min=-3.0176258087158203, max=-3.0176258087158203\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 39, TRAIN LOSS: 0.003405817408654839\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880682945251465, std=nan,           min=-2.7880682945251465, max=-2.7880682945251465\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135674476623535, std=nan,           min=-2.5135674476623535, max=-2.5135674476623535\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105291843414307, std=nan,           min=-2.6105291843414307, max=-2.6105291843414307\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1420254707336426, std=nan,           min=-3.1420254707336426, max=-3.1420254707336426\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.492724895477295, std=nan,           min=-2.492724895477295, max=-2.492724895477295\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.756373643875122, std=nan,           min=-2.756373643875122, max=-2.756373643875122\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735146999359131, std=nan,           min=-5.735146999359131, max=-5.735146999359131\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0176608562469482, std=nan,           min=-3.0176608562469482, max=-3.0176608562469482\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 40, TRAIN LOSS: 0.0027657199116051198\n",
            "TEST ACCURACY: 0.8046875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880778312683105, std=nan,           min=-2.7880778312683105, max=-2.7880778312683105\n",
            "Learning rates : conv1.bias_alpha : mean=-2.513570785522461, std=nan,           min=-2.513570785522461, max=-2.513570785522461\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105377674102783, std=nan,           min=-2.6105377674102783, max=-2.6105377674102783\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.142043113708496, std=nan,           min=-3.142043113708496, max=-3.142043113708496\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927380084991455, std=nan,           min=-2.4927380084991455, max=-2.4927380084991455\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7563910484313965, std=nan,           min=-2.7563910484313965, max=-2.7563910484313965\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735188961029053, std=nan,           min=-5.735188961029053, max=-5.735188961029053\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017677068710327, std=nan,           min=-3.017677068710327, max=-3.017677068710327\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 41, TRAIN LOSS: 0.002386712312363088\n",
            "TEST ACCURACY: 0.828125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880799770355225, std=nan,           min=-2.7880799770355225, max=-2.7880799770355225\n",
            "Learning rates : conv1.bias_alpha : mean=-2.513572931289673, std=nan,           min=-2.513572931289673, max=-2.513572931289673\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610546112060547, std=nan,           min=-2.610546112060547, max=-2.610546112060547\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.142056941986084, std=nan,           min=-3.142056941986084, max=-3.142056941986084\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.492748498916626, std=nan,           min=-2.492748498916626, max=-2.492748498916626\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7563986778259277, std=nan,           min=-2.7563986778259277, max=-2.7563986778259277\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735222816467285, std=nan,           min=-5.735222816467285, max=-5.735222816467285\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0176897048950195, std=nan,           min=-3.0176897048950195, max=-3.0176897048950195\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 42, TRAIN LOSS: 0.002064692314341664\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.788081169128418, std=nan,           min=-2.788081169128418, max=-2.788081169128418\n",
            "Learning rates : conv1.bias_alpha : mean=-2.51357364654541, std=nan,           min=-2.51357364654541, max=-2.51357364654541\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610553503036499, std=nan,           min=-2.610553503036499, max=-2.610553503036499\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1420657634735107, std=nan,           min=-3.1420657634735107, max=-3.1420657634735107\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927518367767334, std=nan,           min=-2.4927518367767334, max=-2.4927518367767334\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.756408214569092, std=nan,           min=-2.756408214569092, max=-2.756408214569092\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735247611999512, std=nan,           min=-5.735247611999512, max=-5.735247611999512\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017698049545288, std=nan,           min=-3.017698049545288, max=-3.017698049545288\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 43, TRAIN LOSS: 0.0018432123606652022\n",
            "TEST ACCURACY: 0.828125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880859375, std=nan,           min=-2.7880859375, max=-2.7880859375\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135741233825684, std=nan,           min=-2.5135741233825684, max=-2.5135741233825684\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105563640594482, std=nan,           min=-2.6105563640594482, max=-2.6105563640594482\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.14207124710083, std=nan,           min=-3.14207124710083, max=-3.14207124710083\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.49275279045105, std=nan,           min=-2.49275279045105, max=-2.49275279045105\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7564141750335693, std=nan,           min=-2.7564141750335693, max=-2.7564141750335693\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735263824462891, std=nan,           min=-5.735263824462891, max=-5.735263824462891\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0177013874053955, std=nan,           min=-3.0177013874053955, max=-3.0177013874053955\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 44, TRAIN LOSS: 0.001651431899368763\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880876064300537, std=nan,           min=-2.7880876064300537, max=-2.7880876064300537\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105592250823975, std=nan,           min=-2.6105592250823975, max=-2.6105592250823975\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.142076015472412, std=nan,           min=-3.142076015472412, max=-3.142076015472412\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927570819854736, std=nan,           min=-2.4927570819854736, max=-2.4927570819854736\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7564196586608887, std=nan,           min=-2.7564196586608887, max=-2.7564196586608887\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.73527193069458, std=nan,           min=-5.73527193069458, max=-5.73527193069458\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0177035331726074, std=nan,           min=-3.0177035331726074, max=-3.0177035331726074\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 45, TRAIN LOSS: 0.0015049321470409632\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.788088798522949, std=nan,           min=-2.788088798522949, max=-2.788088798522949\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610560178756714, std=nan,           min=-2.610560178756714, max=-2.610560178756714\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.142078161239624, std=nan,           min=-3.142078161239624, max=-3.142078161239624\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927589893341064, std=nan,           min=-2.4927589893341064, max=-2.4927589893341064\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7564213275909424, std=nan,           min=-2.7564213275909424, max=-2.7564213275909424\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.73527717590332, std=nan,           min=-5.73527717590332, max=-5.73527717590332\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017705202102661, std=nan,           min=-3.017705202102661, max=-3.017705202102661\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 46, TRAIN LOSS: 0.0013771019374206662\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.788088798522949, std=nan,           min=-2.788088798522949, max=-2.788088798522949\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610560178756714, std=nan,           min=-2.610560178756714, max=-2.610560178756714\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1420786380767822, std=nan,           min=-3.1420786380767822, max=-3.1420786380767822\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.49276065826416, std=nan,           min=-2.49276065826416, max=-2.49276065826416\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7564241886138916, std=nan,           min=-2.7564241886138916, max=-2.7564241886138916\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735279083251953, std=nan,           min=-5.735279083251953, max=-5.735279083251953\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017705202102661, std=nan,           min=-3.017705202102661, max=-3.017705202102661\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 47, TRAIN LOSS: 0.0012692966805398463\n",
            "TEST ACCURACY: 0.796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880890369415283, std=nan,           min=-2.7880890369415283, max=-2.7880890369415283\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.610560894012451, std=nan,           min=-2.610560894012451, max=-2.610560894012451\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1420798301696777, std=nan,           min=-3.1420798301696777, max=-3.1420798301696777\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927620887756348, std=nan,           min=-2.4927620887756348, max=-2.4927620887756348\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.756425619125366, std=nan,           min=-2.756425619125366, max=-2.756425619125366\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.7352776527404785, std=nan,           min=-5.7352776527404785, max=-5.7352776527404785\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.017704963684082, std=nan,           min=-3.017704963684082, max=-3.017704963684082\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 48, TRAIN LOSS: 0.0011739971738308668\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880890369415283, std=nan,           min=-2.7880890369415283, max=-2.7880890369415283\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105611324310303, std=nan,           min=-2.6105611324310303, max=-2.6105611324310303\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.142082452774048, std=nan,           min=-3.142082452774048, max=-3.142082452774048\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927635192871094, std=nan,           min=-2.4927635192871094, max=-2.4927635192871094\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.756427049636841, std=nan,           min=-2.756427049636841, max=-2.756427049636841\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735281467437744, std=nan,           min=-5.735281467437744, max=-5.735281467437744\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0177056789398193, std=nan,           min=-3.0177056789398193, max=-3.0177056789398193\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 49, TRAIN LOSS: 0.0010929098773747683\n",
            "TEST ACCURACY: 0.8125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.7880892753601074, std=nan,           min=-2.7880892753601074, max=-2.7880892753601074\n",
            "Learning rates : conv1.bias_alpha : mean=-2.5135743618011475, std=nan,           min=-2.5135743618011475, max=-2.5135743618011475\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.6105611324310303, std=nan,           min=-2.6105611324310303, max=-2.6105611324310303\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0734074115753174, std=nan,           min=-2.0734074115753174, max=-2.0734074115753174\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-3.1420841217041016, std=nan,           min=-3.1420841217041016, max=-3.1420841217041016\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.1057724952697754, std=nan,           min=-2.1057724952697754, max=-2.1057724952697754\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.4927637577056885, std=nan,           min=-2.4927637577056885, max=-2.4927637577056885\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0090599060058594, std=nan,           min=-2.0090599060058594, max=-2.0090599060058594\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.7564280033111572, std=nan,           min=-2.7564280033111572, max=-2.7564280033111572\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.025712251663208, std=nan,           min=-2.025712251663208, max=-2.025712251663208\n",
            "Learning rates : fc1.weight_alpha : mean=-5.735283374786377, std=nan,           min=-5.735283374786377, max=-5.735283374786377\n",
            "Learning rates : fc1.bias_alpha : mean=-2.021674871444702, std=nan,           min=-2.021674871444702, max=-2.021674871444702\n",
            "Learning rates : fc2.weight_alpha : mean=-3.0177061557769775, std=nan,           min=-3.0177061557769775, max=-3.0177061557769775\n",
            "Learning rates : fc2.bias_alpha : mean=-2.029331684112549, std=nan,           min=-2.029331684112549, max=-2.029331684112549\n",
            "EPOCH: 50, TRAIN LOSS: 0.0010172650723531843\n",
            "TEST ACCURACY: 0.8125\n"
          ]
        }
      ],
      "source": [
        "#SGDLW-SGD optimizer, meaning there is one separate learning rate per layer (or rather per parameter tensor).\n",
        "#Also using the exponential link function for the learning rate.\n",
        "\n",
        "#model2 = MNIST_FullyConnected(28 * 28, 128, 16, 16, 10).to(DEVICE)\n",
        "model2 = CIFAR10_CNN().to(DEVICE)\n",
        "\n",
        "#Create the optimizer\n",
        "optim2 = SGDLayerWise(model2.named_parameters(), -2.0, optimizer=gdtuo.SGD(0.01), device=DEVICE)\n",
        "mw2 = gdtuo.ModuleWrapper(model2, optimizer=optim2)\n",
        "mw2.initialize()\n",
        "\n",
        "train_loss, test_acc, test_loss = train(mw2, record_data=True)\n",
        "save_training_data(train_loss, test_acc, test_loss, \"SGDLW-SGD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjnJ-Mv6Tiv3",
        "outputId": "ae5b3fcc-25e7-4ff7-8e6c-ffea6ba6fea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rates : conv1.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0, std=0.0,           min=-2.0, max=-2.0\n",
            "EPOCH: 1, TRAIN LOSS: 1.6387862657165528\n",
            "TEST ACCURACY: 0.5078125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.000133514404297, std=0.00017930004105437547,           min=-2.0011236667633057, max=-1.9999984502792358\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0026042461395264, std=0.002892902819439769,           min=-2.0096282958984375, max=-2.0000557899475098\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000014305114746, std=6.443484835472191e-06,           min=-2.000110149383545, max=-1.9999998807907104\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0001220703125, std=0.00012674833124037832,           min=-2.0003819465637207, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000001907348633, std=9.496712664258666e-06,           min=-2.0001256465911865, max=-1.9999998807907104\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.000441551208496, std=0.0009177825413644314,           min=-2.00382661819458, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000001907348633, std=6.437366664613364e-06,           min=-2.000152587890625, max=-1.9999995231628418\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0000672340393066, std=8.60458894749172e-05,           min=-2.0003294944763184, max=-2.0\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000014305114746, std=5.885107839276316e-06,           min=-2.000062942504883, max=-1.9999996423721313\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.000230312347412, std=0.0004042512155137956,           min=-2.001552104949951, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000014305114746, std=5.03468027091003e-06,           min=-2.0001821517944336, max=-1.9999995231628418\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0000181198120117, std=2.7652642529574223e-05,           min=-2.000190019607544, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000094175338745, std=0.0002093520452035591,           min=-2.0028350353240967, max=-1.9999994039535522\n",
            "Learning rates : fc2.bias_alpha : mean=-2.00044322013855, std=0.00013767342898063362,           min=-2.000767707824707, max=-2.000312328338623\n",
            "EPOCH: 2, TRAIN LOSS: 1.2532167141723634\n",
            "TEST ACCURACY: 0.53125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.000291347503662, std=0.0003744139976333827,           min=-2.0022823810577393, max=-2.000002145767212\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0052895545959473, std=0.005158374551683664,           min=-2.0161404609680176, max=-2.000195264816284\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.00000262260437, std=9.37717777560465e-06,           min=-2.0001425743103027, max=-1.9999998807907104\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00026273727417, std=0.0002459521929267794,           min=-2.000643730163574, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000033378601074, std=1.6128960851347074e-05,           min=-2.000251293182373, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.000847816467285, std=0.0018431521020829678,           min=-2.008101463317871, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000030994415283, std=1.044484815793112e-05,           min=-2.0002083778381348, max=-1.9999996423721313\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000127077102661, std=0.00014787293912377208,           min=-2.000546932220459, max=-2.0\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000030994415283, std=1.2236910151841585e-05,           min=-2.0002005100250244, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0004465579986572, std=0.0008677166188135743,           min=-2.0038468837738037, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000002384185791, std=8.281592272396665e-06,           min=-2.000227928161621, max=-1.9999996423721313\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0000362396240234, std=4.830874968320131e-05,           min=-2.000274181365967, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000166177749634, std=0.00036427145823836327,           min=-2.004286050796509, max=-1.9999984502792358\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0007903575897217, std=0.00016845860227476805,           min=-2.0010292530059814, max=-2.0005550384521484\n",
            "EPOCH: 3, TRAIN LOSS: 1.107079568901062\n",
            "TEST ACCURACY: 0.640625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0004732608795166, std=0.000567166309338063,           min=-2.003525733947754, max=-2.0000057220458984\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0079383850097656, std=0.0067954775877296925,           min=-2.022084951400757, max=-2.000351667404175\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000033378601074, std=1.2605154552147724e-05,           min=-2.0001704692840576, max=-1.9999996423721313\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.000387191772461, std=0.0003500721650198102,           min=-2.000971794128418, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000052452087402, std=2.4362139811273664e-05,           min=-2.000492572784424, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.001183032989502, std=0.002559575019404292,           min=-2.0114121437072754, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000004529953003, std=1.4671973076474387e-05,           min=-2.000260353088379, max=-1.9999995231628418\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000187635421753, std=0.0001884132798295468,           min=-2.000718593597412, max=-1.9999998807907104\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000005006790161, std=1.8745584384305403e-05,           min=-2.0003223419189453, max=-1.9999994039535522\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0006301403045654, std=0.0011959881521761417,           min=-2.0054209232330322, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000033378601074, std=1.135697584686568e-05,           min=-2.0002706050872803, max=-1.9999995231628418\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0000534057617188, std=6.648007547482848e-05,           min=-2.000343084335327, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000237226486206, std=0.0005267675151117146,           min=-2.0063259601593018, max=-1.9999985694885254\n",
            "Learning rates : fc2.bias_alpha : mean=-2.001131772994995, std=0.00023282968322746456,           min=-2.001575469970703, max=-2.000779628753662\n",
            "EPOCH: 4, TRAIN LOSS: 0.9894156142807007\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0006494522094727, std=0.000737158115953207,           min=-2.0047414302825928, max=-2.0000126361846924\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0106236934661865, std=0.008388182148337364,           min=-2.0275063514709473, max=-2.000459909439087\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000004768371582, std=1.585482641530689e-05,           min=-2.000183582305908, max=-1.9999995231628418\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0005433559417725, std=0.0004680993442889303,           min=-2.001359224319458, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000078678131104, std=3.440775253693573e-05,           min=-2.0007476806640625, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0015411376953125, std=0.003259045770391822,           min=-2.0146660804748535, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000064373016357, std=1.8809674656949937e-05,           min=-2.000288486480713, max=-1.9999995231628418\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0002589225769043, std=0.0002318014157935977,           min=-2.000910520553589, max=-2.0000014305114746\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000006914138794, std=2.5240968170692213e-05,           min=-2.0004332065582275, max=-1.9999996423721313\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0007944107055664, std=0.0014449642039835453,           min=-2.0064878463745117, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000004529953003, std=1.3699225746677257e-05,           min=-2.0003294944763184, max=-1.9999994039535522\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000068187713623, std=7.929471030365676e-05,           min=-2.0003836154937744, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0003013610839844, std=0.000654420058708638,           min=-2.0078723430633545, max=-1.9999990463256836\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0014541149139404, std=0.0002490089973434806,           min=-2.001964569091797, max=-2.001002788543701\n",
            "EPOCH: 5, TRAIN LOSS: 0.9008442317199707\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0008091926574707, std=0.0008971099159680307,           min=-2.0058674812316895, max=-2.0000171661376953\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0131778717041016, std=0.009954683482646942,           min=-2.032557487487793, max=-2.000600576400757\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000059604644775, std=1.9216628061258234e-05,           min=-2.000213146209717, max=-1.9999990463256836\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0006885528564453, std=0.0005615596892312169,           min=-2.0016872882843018, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000109672546387, std=4.373043339001015e-05,           min=-2.0009264945983887, max=-1.9999998807907104\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0018224716186523, std=0.0036727022379636765,           min=-2.0165836811065674, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000081062316895, std=2.270122422487475e-05,           min=-2.000311851501465, max=-1.9999992847442627\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0003209114074707, std=0.0002678280579857528,           min=-2.0010621547698975, max=-2.0000038146972656\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000009059906006, std=3.1765972380526364e-05,           min=-2.000544309616089, max=-1.999999761581421\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0009241104125977, std=0.0016260822303593159,           min=-2.007205009460449, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000054836273193, std=1.560345117468387e-05,           min=-2.000363349914551, max=-1.9999992847442627\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000080108642578, std=8.881529356585816e-05,           min=-2.0004196166992188, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0003604888916016, std=0.0007721696747466922,           min=-2.0089969635009766, max=-1.9999983310699463\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0017285346984863, std=0.00029642885783687234,           min=-2.0023529529571533, max=-2.0011744499206543\n",
            "EPOCH: 6, TRAIN LOSS: 0.8225145074462891\n",
            "TEST ACCURACY: 0.5859375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0009512901306152, std=0.001031173043884337,           min=-2.00667405128479, max=-2.000025749206543\n",
            "Learning rates : conv1.bias_alpha : mean=-2.015481948852539, std=0.011386342346668243,           min=-2.039654493331909, max=-2.0007405281066895\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000007390975952, std=2.2295927919913083e-05,           min=-2.0002498626708984, max=-1.9999994039535522\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.000833034515381, std=0.0006369645707309246,           min=-2.001999855041504, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000014543533325, std=5.323725054040551e-05,           min=-2.001077651977539, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0021073818206787, std=0.004007295705378056,           min=-2.018188953399658, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000009775161743, std=2.6225814508507028e-05,           min=-2.000333070755005, max=-1.9999980926513672\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000375509262085, std=0.0003041137242689729,           min=-2.001194715499878, max=-2.000009298324585\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000112056732178, std=3.8144902646308765e-05,           min=-2.0006377696990967, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0010263919830322, std=0.0017578840488567948,           min=-2.0077083110809326, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000061988830566, std=1.7167323676403612e-05,           min=-2.00038743019104, max=-1.9999990463256836\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000089406967163, std=9.550267714075744e-05,           min=-2.0004565715789795, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0004138946533203, std=0.0008806459372863173,           min=-2.0102007389068604, max=-1.9999992847442627\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0019612312316895, std=0.00035180518170818686,           min=-2.002680540084839, max=-2.001286029815674\n",
            "EPOCH: 7, TRAIN LOSS: 0.7579660877037049\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001091957092285, std=0.00117392442189157,           min=-2.0075597763061523, max=-2.0000298023223877\n",
            "Learning rates : conv1.bias_alpha : mean=-2.017747402191162, std=0.01298076193779707,           min=-2.047644853591919, max=-2.0008010864257812\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000009059906006, std=2.564330497989431e-05,           min=-2.000293254852295, max=-1.9999995231628418\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0009899139404297, std=0.0007167532457970083,           min=-2.0022950172424316, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000018358230591, std=6.468377250712365e-05,           min=-2.001230001449585, max=-1.999999761581421\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.002376079559326, std=0.004286217503249645,           min=-2.0194859504699707, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000011682510376, std=3.0240425985539332e-05,           min=-2.000399589538574, max=-1.9999991655349731\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0004353523254395, std=0.0003488901420496404,           min=-2.0013389587402344, max=-2.0000205039978027\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000014066696167, std=4.624733992386609e-05,           min=-2.0007638931274414, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001126289367676, std=0.0018775335047394037,           min=-2.00815486907959, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000007152557373, std=1.867019454948604e-05,           min=-2.000408411026001, max=-1.9999991655349731\n",
            "Learning rates : fc1.bias_alpha : mean=-2.00009822845459, std=0.00010176774958381429,           min=-2.000493049621582, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0004689693450928, std=0.0009921812452375889,           min=-2.011528730392456, max=-1.9999996423721313\n",
            "Learning rates : fc2.bias_alpha : mean=-2.002185821533203, std=0.000407881016144529,           min=-2.0029890537261963, max=-2.001415967941284\n",
            "EPOCH: 8, TRAIN LOSS: 0.6968992582893372\n",
            "TEST ACCURACY: 0.640625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0012149810791016, std=0.0012983055785298347,           min=-2.0083200931549072, max=-2.0000317096710205\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0197319984436035, std=0.01455428171902895,           min=-2.0559263229370117, max=-2.000894069671631\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000107288360596, std=2.9186847314122133e-05,           min=-2.0003209114074707, max=-1.9999994039535522\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.001142740249634, std=0.0007883964572101831,           min=-2.0025675296783447, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000228881835938, std=7.658758840989321e-05,           min=-2.001371145248413, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.002621650695801, std=0.004536019172519445,           min=-2.020568609237671, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000133514404297, std=3.357243986101821e-05,           min=-2.0004501342773438, max=-1.9999982118606567\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0004870891571045, std=0.000383614853490144,           min=-2.001464366912842, max=-2.0000340938568115\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000016927719116, std=5.464297646540217e-05,           min=-2.0008890628814697, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001213550567627, std=0.0019856730941683054,           min=-2.0085699558258057, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000081062316895, std=1.9913439246010967e-05,           min=-2.000417470932007, max=-1.999998927116394\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001063346862793, std=0.00010645439033396542,           min=-2.0005178451538086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000518560409546, std=0.001080248155631125,           min=-2.012162923812866, max=-1.9999995231628418\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0023891925811768, std=0.00046490589738823473,           min=-2.0032196044921875, max=-2.0015146732330322\n",
            "EPOCH: 9, TRAIN LOSS: 0.6387453165817261\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001332998275757, std=0.0014194899704307318,           min=-2.009037971496582, max=-2.000032901763916\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0215635299682617, std=0.015948137268424034,           min=-2.0625979900360107, max=-2.0009753704071045\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000128746032715, std=3.319429742987268e-05,           min=-2.000361204147339, max=-1.9999990463256836\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0012872219085693, std=0.0008497202070429921,           min=-2.002744674682617, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000027894973755, std=9.061174205271527e-05,           min=-2.001509428024292, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0028491020202637, std=0.004723625257611275,           min=-2.0213332176208496, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000152587890625, std=3.698917498695664e-05,           min=-2.0005075931549072, max=-1.9999967813491821\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0005273818969727, std=0.0004092348681297153,           min=-2.001559019088745, max=-2.0000452995300293\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000202655792236, std=6.353914068313316e-05,           min=-2.0010313987731934, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001286029815674, std=0.0020609695930033922,           min=-2.008784055709839, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000009059906006, std=2.1120986275491305e-05,           min=-2.000429391860962, max=-1.999998927116394\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000112533569336, std=0.0001098227730835788,           min=-2.0005404949188232, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0005671977996826, std=0.0011763923102989793,           min=-2.0132064819335938, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.002570390701294, std=0.0005087040481157601,           min=-2.0034286975860596, max=-2.001631736755371\n",
            "EPOCH: 10, TRAIN LOSS: 0.5869821334266663\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001441478729248, std=0.0015244503738358617,           min=-2.009643316268921, max=-2.0000360012054443\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0232644081115723, std=0.01722758449614048,           min=-2.0686142444610596, max=-2.001051902770996\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000147819519043, std=3.766896406887099e-05,           min=-2.00038743019104, max=-1.999998688697815\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0014336109161377, std=0.0009303585975430906,           min=-2.002901077270508, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000033140182495, std=0.00010575421765679494,           min=-2.0016307830810547, max=-1.9999995231628418\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.003058910369873, std=0.004912726581096649,           min=-2.0220870971679688, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000171661376953, std=4.008705946034752e-05,           min=-2.000547170639038, max=-1.9999961853027344\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0005664825439453, std=0.00043136533349752426,           min=-2.0016393661499023, max=-2.0000503063201904\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.00002384185791, std=7.288117194548249e-05,           min=-2.001203775405884, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0013484954833984, std=0.002133806236088276,           min=-2.009002685546875, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000100135803223, std=2.2416255887947045e-05,           min=-2.000441312789917, max=-1.9999990463256836\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001189708709717, std=0.00011325265950290486,           min=-2.0005671977996826, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0006182193756104, std=0.0012758019147440791,           min=-2.0143141746520996, max=-1.9999995231628418\n",
            "Learning rates : fc2.bias_alpha : mean=-2.002755641937256, std=0.0005728706018999219,           min=-2.0036401748657227, max=-2.0017364025115967\n",
            "EPOCH: 11, TRAIN LOSS: 0.5341810008430481\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001544237136841, std=0.0016207278240472078,           min=-2.010497570037842, max=-2.00003981590271\n",
            "Learning rates : conv1.bias_alpha : mean=-2.024815082550049, std=0.018354199826717377,           min=-2.073575735092163, max=-2.0011086463928223\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000174045562744, std=4.2221938201691955e-05,           min=-2.000432252883911, max=-1.9999995231628418\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.001577854156494, std=0.001008241786621511,           min=-2.0031564235687256, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000388622283936, std=0.00012285324919503182,           min=-2.001757860183716, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0032570362091064, std=0.005104620009660721,           min=-2.0228428840637207, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000019073486328, std=4.324955807533115e-05,           min=-2.000584840774536, max=-1.9999958276748657\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0006046295166016, std=0.0004579064843710512,           min=-2.0017688274383545, max=-2.0000579357147217\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000274181365967, std=8.195891132345423e-05,           min=-2.001315116882324, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0014050006866455, std=0.0022112431470304728,           min=-2.0092835426330566, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000109672546387, std=2.3638054699404165e-05,           min=-2.000454902648926, max=-1.9999988079071045\n",
            "Learning rates : fc1.bias_alpha : mean=-2.00012469291687, std=0.00011582161096157506,           min=-2.0005810260772705, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000666856765747, std=0.0013700068229809403,           min=-2.0152320861816406, max=-1.999999761581421\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0029163360595703, std=0.0006305809947662055,           min=-2.003788948059082, max=-2.0018343925476074\n",
            "EPOCH: 12, TRAIN LOSS: 0.48242050830841066\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0016376972198486, std=0.001712887897156179,           min=-2.0113139152526855, max=-2.0000460147857666\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0262112617492676, std=0.019390970468521118,           min=-2.0776619911193848, max=-2.0011675357818604\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000195503234863, std=4.664798325393349e-05,           min=-2.0004608631134033, max=-1.999998927116394\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.001713275909424, std=0.0010813126573339105,           min=-2.003485679626465, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000044107437134, std=0.00013837763981427997,           min=-2.0018625259399414, max=-1.999998927116394\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0034263134002686, std=0.005279616452753544,           min=-2.023563861846924, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000020742416382, std=4.569913653540425e-05,           min=-2.000603675842285, max=-1.9999985694885254\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0006368160247803, std=0.0004799968155566603,           min=-2.0018997192382812, max=-2.000065326690674\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000030994415283, std=9.080138988792896e-05,           min=-2.001433849334717, max=-1.9999991655349731\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0014522075653076, std=0.002273817313835025,           min=-2.0095295906066895, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000011920928955, std=2.4756474886089563e-05,           min=-2.0004618167877197, max=-1.9999988079071045\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001296997070312, std=0.00011752335558412597,           min=-2.0005898475646973, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.00071120262146, std=0.001451323856599629,           min=-2.0160515308380127, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0030548572540283, std=0.0006859118584543467,           min=-2.0039334297180176, max=-2.001915454864502\n",
            "EPOCH: 13, TRAIN LOSS: 0.4385506968688965\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0017380714416504, std=0.0018107473151758313,           min=-2.0122263431549072, max=-2.000044107437134\n",
            "Learning rates : conv1.bias_alpha : mean=-2.027632713317871, std=0.02053147181868553,           min=-2.082566976547241, max=-2.0012335777282715\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000221729278564, std=5.160659202374518e-05,           min=-2.000519037246704, max=-1.9999994039535522\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0018527507781982, std=0.0011583378072828054,           min=-2.0037975311279297, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000500679016113, std=0.00015588391397614032,           min=-2.0019798278808594, max=-1.9999995231628418\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.003587484359741, std=0.0054219504818320274,           min=-2.02410626411438, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000226497650146, std=4.845303556066938e-05,           min=-2.0006327629089355, max=-1.9999973773956299\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0006680488586426, std=0.0004957075580023229,           min=-2.0019919872283936, max=-2.000075101852417\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000034809112549, std=0.00010072829900309443,           min=-2.0015857219696045, max=-1.9999995231628418\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0014984607696533, std=0.0023218062706291676,           min=-2.0096707344055176, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000128746032715, std=2.5923454813892022e-05,           min=-2.0004701614379883, max=-1.9999983310699463\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001344680786133, std=0.00011921497934963554,           min=-2.0005996227264404, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0007569789886475, std=0.0015392054338008165,           min=-2.016874313354492, max=-1.999999761581421\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0031914710998535, std=0.000744891818612814,           min=-2.0040478706359863, max=-2.001981735229492\n",
            "EPOCH: 14, TRAIN LOSS: 0.39867913224220275\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001833438873291, std=0.0019024638459086418,           min=-2.012953758239746, max=-2.000047206878662\n",
            "Learning rates : conv1.bias_alpha : mean=-2.02897310256958, std=0.021558722481131554,           min=-2.087057590484619, max=-2.0012943744659424\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000247955322266, std=5.6939814385259524e-05,           min=-2.0005857944488525, max=-1.9999992847442627\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0019867420196533, std=0.0012289299629628658,           min=-2.0041229724884033, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000056505203247, std=0.0001747543428791687,           min=-2.0022289752960205, max=-1.9999996423721313\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0037457942962646, std=0.005590888671576977,           min=-2.0248031616210938, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000245571136475, std=5.152657104190439e-05,           min=-2.0006661415100098, max=-1.9999961853027344\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0006954669952393, std=0.0005092271021567285,           min=-2.002073049545288, max=-2.0000836849212646\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000391006469727, std=0.00011131079372717068,           min=-2.001748561859131, max=-1.9999994039535522\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001540184020996, std=0.0023706480860710144,           min=-2.009845733642578, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000014305114746, std=2.7164323910255916e-05,           min=-2.0004847049713135, max=-1.9999982118606567\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000138998031616, std=0.00012083935143891722,           min=-2.000606060028076, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0008037090301514, std=0.0016308192862197757,           min=-2.0180463790893555, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0033180713653564, std=0.0007977776112966239,           min=-2.0042388439178467, max=-2.002054452896118\n",
            "EPOCH: 15, TRAIN LOSS: 0.34592406014442445\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001911163330078, std=0.0019843478221446276,           min=-2.0137414932250977, max=-2.0000476837158203\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0300776958465576, std=0.022457808256149292,           min=-2.0909337997436523, max=-2.001319646835327\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000271797180176, std=6.127511005615816e-05,           min=-2.000629186630249, max=-1.9999992847442627\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0020923614501953, std=0.001279101357795298,           min=-2.004251718521118, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000619888305664, std=0.00019127798441331834,           min=-2.0025811195373535, max=-1.9999994039535522\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.003861427307129, std=0.0057065109722316265,           min=-2.0252673625946045, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000264644622803, std=5.383681127568707e-05,           min=-2.0006816387176514, max=-1.9999972581863403\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000720739364624, std=0.0005259471363388002,           min=-2.0021610260009766, max=-2.000089168548584\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000042676925659, std=0.00012085313210263848,           min=-2.001917839050293, max=-1.9999994039535522\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001572370529175, std=0.002407972700893879,           min=-2.0099740028381348, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000150203704834, std=2.8157619453850202e-05,           min=-2.0004916191101074, max=-1.9999983310699463\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001425743103027, std=0.0001218205361510627,           min=-2.0006113052368164, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0008440017700195, std=0.0017047077417373657,           min=-2.0186045169830322, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003422498703003, std=0.0008576351683586836,           min=-2.0044491291046143, max=-2.002110719680786\n",
            "EPOCH: 16, TRAIN LOSS: 0.3111404387283325\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.001993179321289, std=0.002063116291537881,           min=-2.0144431591033936, max=-2.0000483989715576\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0311689376831055, std=0.02332388423383236,           min=-2.0943164825439453, max=-2.001352071762085\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000030040740967, std=6.666975241387263e-05,           min=-2.000685691833496, max=-1.9999983310699463\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0022048950195312, std=0.001335532171651721,           min=-2.0044946670532227, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000067949295044, std=0.00020837082411162555,           min=-2.002800703048706, max=-1.9999994039535522\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0039777755737305, std=0.005846743006259203,           min=-2.0258820056915283, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000028371810913, std=5.6931294238893315e-05,           min=-2.0007264614105225, max=-1.999997615814209\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0007410049438477, std=0.0005384000251069665,           min=-2.002218246459961, max=-2.000092029571533\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000046968460083, std=0.0001314517721766606,           min=-2.002082109451294, max=-1.9999994039535522\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001603126525879, std=0.002439638366922736,           min=-2.010071039199829, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000016212463379, std=2.9252758395159617e-05,           min=-2.000500202178955, max=-1.9999980926513672\n",
            "Learning rates : fc1.bias_alpha : mean=-2.00014591217041, std=0.00012306675489526242,           min=-2.000617265701294, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000882863998413, std=0.0017788882832974195,           min=-2.019329309463501, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003514528274536, std=0.000909626018255949,           min=-2.0046446323394775, max=-2.0021588802337646\n",
            "EPOCH: 17, TRAIN LOSS: 0.27345380975723266\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0020692348480225, std=0.0021370258182287216,           min=-2.015056610107422, max=-2.000046491622925\n",
            "Learning rates : conv1.bias_alpha : mean=-2.032214403152466, std=0.02417026460170746,           min=-2.0976264476776123, max=-2.0014021396636963\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000032901763916, std=7.242950960062444e-05,           min=-2.0007574558258057, max=-1.9999990463256836\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0023112297058105, std=0.0014077546074986458,           min=-2.0048012733459473, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000741481781006, std=0.0002254909195471555,           min=-2.0030670166015625, max=-1.9999990463256836\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0040807723999023, std=0.005965210031718016,           min=-2.0263760089874268, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000030517578125, std=6.009312710375525e-05,           min=-2.0007641315460205, max=-1.9999974966049194\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000762939453125, std=0.0005513397045433521,           min=-2.002286911010742, max=-2.0001003742218018\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000051259994507, std=0.00014177366392686963,           min=-2.0022287368774414, max=-1.9999990463256836\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0016307830810547, std=0.002474151086062193,           min=-2.010207176208496, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000171661376953, std=3.0438759495154954e-05,           min=-2.0005080699920654, max=-1.9999980926513672\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001487731933594, std=0.0001242175349034369,           min=-2.000622034072876, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.00091814994812, std=0.0018385752337053418,           min=-2.01991868019104, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0035922527313232, std=0.0009512716205790639,           min=-2.004772186279297, max=-2.0022032260894775\n",
            "EPOCH: 18, TRAIN LOSS: 0.23343996988773347\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002129554748535, std=0.0021965866908431053,           min=-2.015570878982544, max=-2.0000476837158203\n",
            "Learning rates : conv1.bias_alpha : mean=-2.033048391342163, std=0.024788454174995422,           min=-2.0998482704162598, max=-2.001420736312866\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000035047531128, std=7.743861351627856e-05,           min=-2.000793933868408, max=-1.9999990463256836\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00239896774292, std=0.0014551208587363362,           min=-2.005019426345825, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.00007963180542, std=0.00024162941554095596,           min=-2.00333571434021, max=-1.9999990463256836\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0041682720184326, std=0.006073725875467062,           min=-2.0268430709838867, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000032424926758, std=6.25583779765293e-05,           min=-2.0007810592651367, max=-1.9999967813491821\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0007805824279785, std=0.0005615301197394729,           min=-2.002340078353882, max=-2.00010347366333\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000550746917725, std=0.0001512956660008058,           min=-2.002403736114502, max=-1.9999985694885254\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001655101776123, std=0.002506920835003257,           min=-2.0103414058685303, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000181198120117, std=3.1310981285059825e-05,           min=-2.0005111694335938, max=-1.999997854232788\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000150680541992, std=0.00012483294995035976,           min=-2.0006253719329834, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0009498596191406, std=0.00190146011300385,           min=-2.020339250564575, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0036537647247314, std=0.0009923669276759028,           min=-2.0049195289611816, max=-2.0022358894348145\n",
            "EPOCH: 19, TRAIN LOSS: 0.20794877772569656\n",
            "TEST ACCURACY: 0.71875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002202272415161, std=0.0022681942209601402,           min=-2.016075849533081, max=-2.0000531673431396\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0338997840881348, std=0.025471698492765427,           min=-2.1029529571533203, max=-2.001453399658203\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000037431716919, std=8.183111640391871e-05,           min=-2.000818967819214, max=-1.9999984502792358\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0024776458740234, std=0.001499289064668119,           min=-2.005194902420044, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.00008487701416, std=0.000257355161011219,           min=-2.003634214401245, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004244327545166, std=0.006157478783279657,           min=-2.027172803878784, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000340938568115, std=6.487915379693732e-05,           min=-2.0007858276367188, max=-1.9999974966049194\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000797748565674, std=0.0005710195400752127,           min=-2.002382278442383, max=-2.0001060962677\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.00005841255188, std=0.00016047088138293475,           min=-2.0025248527526855, max=-1.9999988079071045\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0016751289367676, std=0.0025312004145234823,           min=-2.010417938232422, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000019073486328, std=3.225570617360063e-05,           min=-2.000518321990967, max=-1.999997854232788\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000152587890625, std=0.00012535895803011954,           min=-2.000628709793091, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.000983715057373, std=0.00196677353233099,           min=-2.02107310295105, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003713369369507, std=0.001027905847877264,           min=-2.0050179958343506, max=-2.0022659301757812\n",
            "EPOCH: 20, TRAIN LOSS: 0.1794655097961426\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002260208129883, std=0.002319335239008069,           min=-2.0164897441864014, max=-2.000053644180298\n",
            "Learning rates : conv1.bias_alpha : mean=-2.034604549407959, std=0.02602134644985199,           min=-2.105356216430664, max=-2.0014803409576416\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000040054321289, std=8.659555169288069e-05,           min=-2.000871419906616, max=-1.999998688697815\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.002556800842285, std=0.0015384602593258023,           min=-2.005345582962036, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0000903606414795, std=0.0002725740778259933,           min=-2.0039196014404297, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0043110847473145, std=0.006226523779332638,           min=-2.027405023574829, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000362396240234, std=6.761755503248423e-05,           min=-2.000803232192993, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000817060470581, std=0.0005826774286106229,           min=-2.0024478435516357, max=-2.000110149383545\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000622272491455, std=0.00017034349730238318,           min=-2.0027105808258057, max=-1.9999982118606567\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001692295074463, std=0.0025516210589557886,           min=-2.0104784965515137, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000200271606445, std=3.320534960948862e-05,           min=-2.0005311965942383, max=-1.999997854232788\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000154495239258, std=0.00012581983173731714,           min=-2.0006301403045654, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0010128021240234, std=0.002023180015385151,           min=-2.0215871334075928, max=-1.999999761581421\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0037593841552734, std=0.0010546331759542227,           min=-2.0051157474517822, max=-2.0022904872894287\n",
            "EPOCH: 21, TRAIN LOSS: 0.17203670748233796\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0023319721221924, std=0.0023868384305387735,           min=-2.0170044898986816, max=-2.0000545978546143\n",
            "Learning rates : conv1.bias_alpha : mean=-2.035496234893799, std=0.02674129791557789,           min=-2.1083765029907227, max=-2.0015010833740234\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000429153442383, std=9.250663424609229e-05,           min=-2.0009493827819824, max=-1.9999988079071045\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0026450157165527, std=0.0015941184246912599,           min=-2.0055594444274902, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000096559524536, std=0.00029014842584729195,           min=-2.0042214393615723, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004387617111206, std=0.006306910887360573,           min=-2.0277395248413086, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000391006469727, std=7.155804632930085e-05,           min=-2.0008370876312256, max=-1.9999964237213135\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000839948654175, std=0.0005958593683317304,           min=-2.002525806427002, max=-2.0001180171966553\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000669956207275, std=0.0001825344079406932,           min=-2.0029356479644775, max=-1.9999988079071045\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001713991165161, std=0.002575839404016733,           min=-2.0105669498443604, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000021457672119, std=3.431626100791618e-05,           min=-2.0005440711975098, max=-1.999997854232788\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001564025878906, std=0.00012648609117604792,           min=-2.000633955001831, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0010452270507812, std=0.0020832973532378674,           min=-2.021989345550537, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003810167312622, std=0.0010891567217186093,           min=-2.005270481109619, max=-2.0023181438446045\n",
            "EPOCH: 22, TRAIN LOSS: 0.13124796890258789\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0023715496063232, std=0.0024279742501676083,           min=-2.0173892974853516, max=-2.0000526905059814\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0360465049743652, std=0.027241159230470657,           min=-2.1105668544769287, max=-2.0015246868133545\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000044584274292, std=9.583956853020936e-05,           min=-2.0009844303131104, max=-1.9999985694885254\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.002694606781006, std=0.0016194964991882443,           min=-2.005643606185913, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000100612640381, std=0.0003019346622750163,           min=-2.004507064819336, max=-1.9999994039535522\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004434585571289, std=0.0063463859260082245,           min=-2.027864694595337, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000405311584473, std=7.335713598877192e-05,           min=-2.0008487701416016, max=-1.9999961853027344\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008513927459717, std=0.0006034729885868728,           min=-2.002561569213867, max=-2.0001187324523926\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000696182250977, std=0.0001896469620987773,           min=-2.0030503273010254, max=-1.9999988079071045\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0017249584198, std=0.002587579656392336,           min=-2.0105972290039062, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000219345092773, std=3.492109681246802e-05,           min=-2.0005502700805664, max=-1.9999961853027344\n",
            "Learning rates : fc1.bias_alpha : mean=-2.000157356262207, std=0.00012680227519012988,           min=-2.0006356239318848, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.001065492630005, std=0.0021221665665507317,           min=-2.0224201679229736, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0038373470306396, std=0.0011043996782973409,           min=-2.0053250789642334, max=-2.0023317337036133\n",
            "EPOCH: 23, TRAIN LOSS: 0.1061800790834427\n",
            "TEST ACCURACY: 0.7265625\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0024054050445557, std=0.002457095542922616,           min=-2.0175576210021973, max=-2.0000545978546143\n",
            "Learning rates : conv1.bias_alpha : mean=-2.036426067352295, std=0.02753165364265442,           min=-2.1117279529571533, max=-2.0015501976013184\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000462532043457, std=9.875720570562407e-05,           min=-2.001008987426758, max=-1.9999982118606567\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0027360916137695, std=0.001643577590584755,           min=-2.0057616233825684, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000103712081909, std=0.00031095638405531645,           min=-2.0046167373657227, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0044686794281006, std=0.006386886350810528,           min=-2.0280354022979736, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000414848327637, std=7.502786320401356e-05,           min=-2.0008697509765625, max=-1.999996304512024\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008580684661865, std=0.000606369343586266,           min=-2.002575159072876, max=-2.000119686126709\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000715255737305, std=0.00019539361528586596,           min=-2.0031163692474365, max=-1.9999969005584717\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0017330646514893, std=0.002597751095890999,           min=-2.0106375217437744, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000224113464355, std=3.5394859878579155e-05,           min=-2.0005578994750977, max=-1.9999973773956299\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001578330993652, std=0.00012693091412074864,           min=-2.000636100769043, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.001082420349121, std=0.0021542811300605536,           min=-2.0227084159851074, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0038564205169678, std=0.0011166363256052136,           min=-2.0053629875183105, max=-2.0023419857025146\n",
            "EPOCH: 24, TRAIN LOSS: 0.10717828913211823\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0024478435516357, std=0.0024960716255009174,           min=-2.0178451538085938, max=-2.0000569820404053\n",
            "Learning rates : conv1.bias_alpha : mean=-2.036930799484253, std=0.027875499799847603,           min=-2.1130964756011963, max=-2.0015811920166016\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000486373901367, std=0.00010328819189453498,           min=-2.001039981842041, max=-1.9999982118606567\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.002790927886963, std=0.0016821641474962234,           min=-2.006028890609741, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0001089572906494, std=0.0003246614942327142,           min=-2.004788637161255, max=-1.9999991655349731\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0045175552368164, std=0.006453860085457563,           min=-2.0283260345458984, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000431537628174, std=7.724072929704562e-05,           min=-2.000884532928467, max=-1.9999947547912598\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008695125579834, std=0.000612610368989408,           min=-2.0026073455810547, max=-2.0001237392425537\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000075340270996, std=0.00020479601516854018,           min=-2.00325870513916, max=-1.9999969005584717\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0017459392547607, std=0.002613537246361375,           min=-2.0106821060180664, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.000023365020752, std=3.624216697062366e-05,           min=-2.000572443008423, max=-1.9999970197677612\n",
            "Learning rates : fc1.bias_alpha : mean=-2.00015926361084, std=0.00012740211968775839,           min=-2.000638008117676, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011043548583984, std=0.002190015045925975,           min=-2.0231289863586426, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0038838386535645, std=0.0011344571830704808,           min=-2.005398750305176, max=-2.002352476119995\n",
            "EPOCH: 25, TRAIN LOSS: 0.09121926994204521\n",
            "TEST ACCURACY: 0.7109375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0024890899658203, std=0.002538213972002268,           min=-2.018129825592041, max=-2.000059127807617\n",
            "Learning rates : conv1.bias_alpha : mean=-2.037445545196533, std=0.02837199531495571,           min=-2.1157073974609375, max=-2.0016047954559326\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000505447387695, std=0.00010703478619689122,           min=-2.00107741355896, max=-1.9999979734420776\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0028343200683594, std=0.001704455236904323,           min=-2.0061044692993164, max=-2.0\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0001118183135986, std=0.00033445103326812387,           min=-2.004948616027832, max=-1.9999985694885254\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004549980163574, std=0.00648109707981348,           min=-2.028416872024536, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.00004506111145, std=7.961970550240949e-05,           min=-2.00089955329895, max=-1.9999961853027344\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000880241394043, std=0.000615687808021903,           min=-2.002617597579956, max=-2.000128984451294\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000784397125244, std=0.00021301658125594258,           min=-2.003476858139038, max=-1.9999977350234985\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0017566680908203, std=0.0026215645484626293,           min=-2.010698080062866, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.00002384185791, std=3.683419345179573e-05,           min=-2.0005791187286377, max=-1.9999969005584717\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001602172851562, std=0.00012760380923282355,           min=-2.000638484954834, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011208057403564, std=0.0022183088585734367,           min=-2.0233349800109863, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003904104232788, std=0.0011467223521322012,           min=-2.0054256916046143, max=-2.0023574829101562\n",
            "EPOCH: 26, TRAIN LOSS: 0.07560825345516205\n",
            "TEST ACCURACY: 0.703125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002514362335205, std=0.002559845568612218,           min=-2.018315076828003, max=-2.0000619888305664\n",
            "Learning rates : conv1.bias_alpha : mean=-2.037717580795288, std=0.02859111875295639,           min=-2.1166000366210938, max=-2.0016143321990967\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000051736831665, std=0.00010949243005597964,           min=-2.001089334487915, max=-1.999997615814209\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.002861499786377, std=0.001720984815619886,           min=-2.0061774253845215, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0001144409179688, std=0.0003424766764510423,           min=-2.0051348209381104, max=-1.9999979734420776\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0045738220214844, std=0.006505083292722702,           min=-2.0284974575042725, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000460147857666, std=8.097142563201487e-05,           min=-2.000892162322998, max=-1.9999960660934448\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008859634399414, std=0.0006193731096573174,           min=-2.002636671066284, max=-2.0001308917999268\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000803470611572, std=0.00021853914950042963,           min=-2.0036375522613525, max=-1.9999967813491821\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.0017619132995605, std=0.002627616049721837,           min=-2.0107147693634033, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000243186950684, std=3.727979856193997e-05,           min=-2.000581979751587, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001606941223145, std=0.00012765578867401928,           min=-2.0006392002105713, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.001136064529419, std=0.002252743346616626,           min=-2.0236854553222656, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039167404174805, std=0.0011529246112331748,           min=-2.0054495334625244, max=-2.002364158630371\n",
            "EPOCH: 27, TRAIN LOSS: 0.06881112637281418\n",
            "TEST ACCURACY: 0.6484375\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0025370121002197, std=0.0025783523451536894,           min=-2.0184433460235596, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.037973642349243, std=0.028783852234482765,           min=-2.1174192428588867, max=-2.001633405685425\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.0000529289245605, std=0.00011206728959223256,           min=-2.0011157989501953, max=-1.9999967813491821\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0028862953186035, std=0.0017356520984321833,           min=-2.0062217712402344, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000117301940918, std=0.00035000185016542673,           min=-2.0052895545959473, max=-1.9999983310699463\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0045952796936035, std=0.006529034115374088,           min=-2.0286009311676025, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.000047206878662, std=8.251899998867884e-05,           min=-2.000904083251953, max=-1.9999955892562866\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008909702301025, std=0.0006222049123607576,           min=-2.0026516914367676, max=-2.0001330375671387\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.000082015991211, std=0.00022270165209192783,           min=-2.0037083625793457, max=-1.9999964237213135\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001767158508301, std=0.0026333206333220005,           min=-2.0107336044311523, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000247955322266, std=3.7629219150403515e-05,           min=-2.000581741333008, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001611709594727, std=0.00012766376312356442,           min=-2.0006394386291504, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.001147747039795, std=0.00227934867143631,           min=-2.0241053104400635, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039258003234863, std=0.0011582174338400364,           min=-2.005467653274536, max=-2.0023679733276367\n",
            "EPOCH: 28, TRAIN LOSS: 0.04404840421795845\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0025506019592285, std=0.0025905934162437916,           min=-2.018507242202759, max=-2.000062942504883\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038120985031128, std=0.028874129056930542,           min=-2.1178359985351562, max=-2.00164532661438\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000053882598877, std=0.00011380283103790134,           min=-2.001145601272583, max=-1.9999967813491821\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0029022693634033, std=0.0017433803295716643,           min=-2.0062127113342285, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0001187324523926, std=0.000354418414644897,           min=-2.005305528640747, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0046064853668213, std=0.006536349654197693,           min=-2.0286264419555664, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.35294631542638e-05,           min=-2.0009119510650635, max=-1.9999958276748657\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008935928344727, std=0.000623498868662864,           min=-2.0026538372039795, max=-2.000133991241455\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000829696655273, std=0.00022538720804732293,           min=-2.0037341117858887, max=-1.9999971389770508\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001769542694092, std=0.0026355839800089598,           min=-2.0107436180114746, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.786351589951664e-05,           min=-2.000582456588745, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.00012773786147590727,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.001154899597168, std=0.002292731311172247,           min=-2.0242409706115723, max=-2.0\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039308071136475, std=0.0011606549378484488,           min=-2.005472421646118, max=-2.002368688583374\n",
            "EPOCH: 29, TRAIN LOSS: 0.03217817832708359\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.0025575160980225, std=0.002597105223685503,           min=-2.0185532569885254, max=-2.000062942504883\n",
            "Learning rates : conv1.bias_alpha : mean=-2.0381922721862793, std=0.028928199782967567,           min=-2.118102550506592, max=-2.001643180847168\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000053882598877, std=0.00011430376616772264,           min=-2.0011489391326904, max=-1.9999970197677612\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.0029096603393555, std=0.001747568603605032,           min=-2.0062105655670166, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.0001189708709717, std=0.0003561556513886899,           min=-2.00533390045166, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.0046114921569824, std=0.006541482638567686,           min=-2.028644561767578, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.390879520447925e-05,           min=-2.000917911529541, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.000894784927368, std=0.0006241613882593811,           min=-2.002655506134033, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000832080841064, std=0.00022656247892882675,           min=-2.0037455558776855, max=-1.9999971389770508\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.002636909717693925,           min=-2.0107462406158447, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.794996882788837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.00012776051880791783,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011584758758545, std=0.002298509469255805,           min=-2.0242855548858643, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.003932237625122, std=0.0011616679839789867,           min=-2.0054759979248047, max=-2.0023703575134277\n",
            "EPOCH: 30, TRAIN LOSS: 0.011726636402904988\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.002598060993477702,           min=-2.0185658931732178, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.028937172144651413,           min=-2.1181352138519287, max=-2.001641035079956\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450512829469517,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484999261796474,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565272781997919,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542903836816549,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400074148084968e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.0002267263480462134,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.796849341597408e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995450999587774,           min=-2.0242931842803955, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 31, TRAIN LOSS: 0.003933218999058008\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980621576309204,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893735282123089,           min=-2.1181349754333496, max=-2.001640796661377\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450226156739518,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565295191947371,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672500927001238,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.796856617555022e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995658218860626,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 32, TRAIN LOSS: 0.0021061182815767824\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450064630480483,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565295191947371,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.796856617555022e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.002299571642652154,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 33, TRAIN LOSS: 0.001366656776033342\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.796856617555022e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 34, TRAIN LOSS: 0.0011535181377641858\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 35, TRAIN LOSS: 0.0009239360350370407\n",
            "TEST ACCURACY: 0.6953125\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 36, TRAIN LOSS: 0.0007847240309230983\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 37, TRAIN LOSS: 0.0006878403516020626\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 38, TRAIN LOSS: 0.000622528611626476\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 39, TRAIN LOSS: 0.0005693821495771408\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 40, TRAIN LOSS: 0.0005228138869814575\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 41, TRAIN LOSS: 0.000485056049991399\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 42, TRAIN LOSS: 0.0004507775769010186\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 43, TRAIN LOSS: 0.0004229886606708169\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 44, TRAIN LOSS: 0.00039746293063275517\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 45, TRAIN LOSS: 0.00037429675300605593\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 46, TRAIN LOSS: 0.0003553826019912958\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 47, TRAIN LOSS: 0.00033681699784472583\n",
            "TEST ACCURACY: 0.671875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 48, TRAIN LOSS: 0.0003209167554508895\n",
            "TEST ACCURACY: 0.6796875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 49, TRAIN LOSS: 0.0003057981710601598\n",
            "TEST ACCURACY: 0.6875\n",
            "Learning rates : conv1.weight_alpha : mean=-2.002558708190918, std=0.0025980628561228514,           min=-2.018566131591797, max=-2.0000627040863037\n",
            "Learning rates : conv1.bias_alpha : mean=-2.038203239440918, std=0.02893739752471447,           min=-2.1181349754333496, max=-2.001640558242798\n",
            "Learning rates : res1.conv1.weight_alpha : mean=-2.000054359436035, std=0.00011450157762737945,           min=-2.0011496543884277, max=-1.9999971389770508\n",
            "Learning rates : res1.conv1.bias_alpha : mean=-2.00291109085083, std=0.0017484852578490973,           min=-2.0062167644500732, max=-2.000000238418579\n",
            "Learning rates : res1.conv2.weight_alpha : mean=-2.000119209289551, std=0.0003565297811292112,           min=-2.0053398609161377, max=-1.9999980926513672\n",
            "Learning rates : res1.conv2.bias_alpha : mean=-2.004612445831299, std=0.006542895920574665,           min=-2.028649091720581, max=-2.0\n",
            "Learning rates : res2.conv1.weight_alpha : mean=-2.0000479221343994, std=8.400023216381669e-05,           min=-2.000917673110962, max=-1.9999966621398926\n",
            "Learning rates : res2.conv1.bias_alpha : mean=-2.0008950233459473, std=0.0006241825758479536,           min=-2.0026559829711914, max=-2.0001344680786133\n",
            "Learning rates : res2.conv2.weight_alpha : mean=-2.0000834465026855, std=0.00022672479099128395,           min=-2.0037448406219482, max=-1.9999970197677612\n",
            "Learning rates : res2.conv2.bias_alpha : mean=-2.001770496368408, std=0.0026371399872004986,           min=-2.010746717453003, max=-2.0\n",
            "Learning rates : fc1.weight_alpha : mean=-2.0000252723693848, std=3.7968573451507837e-05,           min=-2.000582695007324, max=-1.9999971389770508\n",
            "Learning rates : fc1.bias_alpha : mean=-2.0001614093780518, std=0.0001277649134863168,           min=-2.0006399154663086, max=-2.0\n",
            "Learning rates : fc2.weight_alpha : mean=-2.0011589527130127, std=0.0022995714098215103,           min=-2.0242934226989746, max=-1.9999998807907104\n",
            "Learning rates : fc2.bias_alpha : mean=-2.0039327144622803, std=0.0011617228155955672,           min=-2.005476236343384, max=-2.002370595932007\n",
            "EPOCH: 50, TRAIN LOSS: 0.0002926740665314719\n",
            "TEST ACCURACY: 0.6796875\n"
          ]
        }
      ],
      "source": [
        "#SGDPW-SGD optimizer, meaning there is one separate learning rate per parameter.\n",
        "#Also using the exponential link function for the learning rate.\n",
        "\n",
        "#model3 = MNIST_FullyConnected(28 * 28, 128, 16, 16, 10).to(DEVICE)\n",
        "model3 = CIFAR10_CNN().to(DEVICE)\n",
        "\n",
        "#Create the optimizer\n",
        "optim3 = SGDParamWise(model3.named_parameters(), -2.0, optimizer=gdtuo.SGD(0.01), device=DEVICE)\n",
        "mw3 = gdtuo.ModuleWrapper(model3, optimizer=optim3)\n",
        "mw3.initialize()\n",
        "\n",
        "train_loss, test_acc, test_loss = train(mw3, record_data=True)\n",
        "save_training_data(train_loss, test_acc, test_loss, \"SGDPW-SGD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "wuFc0fR6SwJb",
        "outputId": "4d27ca8c-1aa0-4bde-eae7-fb8a9648f7a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SGD-SGD 19550 50 50\n",
            "SGDLW-SGD 19550 50 50\n",
            "SGDExp-SGD 19550 50 50\n",
            "SGD 19550 50 50\n",
            "SGDPW-SGD 19550 50 50\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_comparison(names):\n",
        "  '''\n",
        "  names : list of names\n",
        "  '''\n",
        "  colors = ['r', 'b', 'g', 'm', 'y', 'TOOMANYCOLORS']\n",
        "  trlosses = []\n",
        "  accs = []\n",
        "  losses = []\n",
        "  sample_freq = 50\n",
        "  for n in names:\n",
        "    t, a, l = load_training_data(n)\n",
        "    trlosses.append(t[::sample_freq])\n",
        "    accs.append(a)\n",
        "    losses.append(l)\n",
        "    print(n, len(t), len(a), len(l))\n",
        "\n",
        "\n",
        "  fig, axs = plt.subplots(2, 2)\n",
        "  trdata_x = torch.linspace(0, len(accs[0]), len(trlosses[0]))\n",
        "  axs[0][0].set_title(\"Training loss\")\n",
        "  axs[0][1].set_title(\"Testset loss\")\n",
        "  axs[1][0].set_title(\"Testset acc\")\n",
        "  for n, t, a, l, c in zip(names, trlosses, accs, losses, colors):\n",
        "    axs[0][0].plot(trdata_x, t, color=c, label=n)\n",
        "    axs[0][1].plot(range(1, len(l)+1), l, color=c)\n",
        "    axs[1][0].plot(range(1, len(a)+1), a, color=c)\n",
        "\n",
        "  #axs[0][0].legend()\n",
        "  #axs[1][1].set_visible(False)\n",
        "\n",
        "  for ax in axs.flatten():\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "\n",
        "  fig.delaxes(axs[1][1])\n",
        "  fig.legend(loc='lower right', bbox_to_anchor=(0.8, 0.2))\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_comparison([\"SGD-SGD\", \"SGDLW-SGD\", \"SGDExp-SGD\", \"SGD\", \"SGDPW-SGD\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-P68_ffXMmY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
