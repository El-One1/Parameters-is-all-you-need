{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the positive definite matrix.\n",
    "N = 5\n",
    "L = torch.randn(N, N)\n",
    "A = L @ L.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 0., 0., 0., 0.],\n",
      "        [0., 4., 0., 0., 0.],\n",
      "        [0., 0., 3., 0., 0.],\n",
      "        [0., 0., 0., 2., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "tensor(0.4000)\n",
      "x_star=tensor([-1.0000e+00, -4.7019e-04, -3.2768e-11,  3.2768e-11,  4.7018e-04],\n",
      "       requires_grad=True), iterations=15\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the quadratic form function\n",
    "def quadratic_form(x, A):\n",
    "    return 0.5 * torch.matmul(torch.matmul(x.t(), A), x)\n",
    "\n",
    "# Define the gradient descent function, returning optimal point AND number of iterations\n",
    "def gradient_descent(A, learning_rate, x0=None, max_iter=1000):\n",
    "    # Initialize the starting point\n",
    "    x = x0 if x0 is not None else torch.randn(A.shape[0], 1)\n",
    "    x.requires_grad = True\n",
    "        \n",
    "    # Perform gradient descent\n",
    "    precision = 1e-6\n",
    "    prev_loss = float('inf')\n",
    "    iterations = 0\n",
    "    while iterations < max_iter:\n",
    "        # Compute the loss\n",
    "        loss = quadratic_form(x, A)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if torch.abs(loss - prev_loss) < precision:\n",
    "            break\n",
    "        \n",
    "        # Update the parameters\n",
    "        x.grad = None\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            x -= learning_rate * x.grad\n",
    "        iterations += 1\n",
    "        \n",
    "        if iterations%10000 == 0:\n",
    "            print(loss.item(), x)\n",
    "\n",
    "        \n",
    "        # Update the previous loss\n",
    "        prev_loss = loss\n",
    "    \n",
    "    # Return the optimized solution\n",
    "    return x, iterations\n",
    "\n",
    "# Define a symmetric matrix with fixed eigenvalues\n",
    "A = torch.diag(torch.tensor([5., 4., 3., 2., 1.]))\n",
    "print(A)\n",
    "\n",
    "# Theoretically optimal learning rate\n",
    "lr = 2.0 / (torch.max(A) + torch.min(A))\n",
    "print(lr)\n",
    "\n",
    "# Perform gradient descent\n",
    "x_star, iterations = gradient_descent(A, lr, x0 = torch.tensor([1., 1, 1, 1, 1]))\n",
    "print(f\"{x_star=}, {iterations=}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate=tensor(0.0100), iterations=459, converged=True\n",
      "learning_rate=tensor(0.0200), iterations=246, converged=True\n",
      "learning_rate=tensor(0.0300), iterations=170, converged=True\n",
      "learning_rate=tensor(0.0400), iterations=131, converged=True\n",
      "learning_rate=tensor(0.0500), iterations=107, converged=True\n",
      "learning_rate=tensor(0.0600), iterations=90, converged=True\n",
      "learning_rate=tensor(0.0700), iterations=78, converged=True\n",
      "learning_rate=tensor(0.0800), iterations=69, converged=True\n",
      "learning_rate=tensor(0.0900), iterations=62, converged=True\n",
      "learning_rate=tensor(0.1000), iterations=56, converged=True\n",
      "learning_rate=tensor(0.1100), iterations=51, converged=True\n",
      "learning_rate=tensor(0.1200), iterations=47, converged=True\n",
      "learning_rate=tensor(0.1300), iterations=44, converged=True\n",
      "learning_rate=tensor(0.1400), iterations=41, converged=True\n",
      "learning_rate=tensor(0.1500), iterations=38, converged=True\n",
      "learning_rate=tensor(0.1600), iterations=36, converged=True\n",
      "learning_rate=tensor(0.1700), iterations=34, converged=True\n",
      "learning_rate=tensor(0.1800), iterations=32, converged=True\n",
      "learning_rate=tensor(0.1900), iterations=30, converged=True\n",
      "learning_rate=tensor(0.2000), iterations=29, converged=True\n",
      "learning_rate=tensor(0.2100), iterations=27, converged=True\n",
      "learning_rate=tensor(0.2200), iterations=26, converged=True\n",
      "learning_rate=tensor(0.2300), iterations=25, converged=True\n",
      "learning_rate=tensor(0.2400), iterations=24, converged=True\n",
      "learning_rate=tensor(0.2500), iterations=23, converged=True\n",
      "learning_rate=tensor(0.2600), iterations=22, converged=True\n",
      "learning_rate=tensor(0.2700), iterations=21, converged=True\n",
      "learning_rate=tensor(0.2800), iterations=20, converged=True\n",
      "learning_rate=tensor(0.2900), iterations=20, converged=True\n",
      "learning_rate=tensor(0.3000), iterations=19, converged=True\n",
      "learning_rate=tensor(0.3100), iterations=18, converged=True\n",
      "learning_rate=tensor(0.3200), iterations=18, converged=True\n",
      "learning_rate=tensor(0.3300), iterations=18, converged=True\n",
      "learning_rate=tensor(0.3400), iterations=21, converged=True\n",
      "learning_rate=tensor(0.3500), iterations=26, converged=True\n",
      "learning_rate=tensor(0.3600), iterations=32, converged=True\n",
      "learning_rate=tensor(0.3700), iterations=43, converged=True\n",
      "learning_rate=tensor(0.3800), iterations=64, converged=True\n",
      "learning_rate=tensor(0.3900), iterations=122, converged=True\n",
      "learning_rate=tensor(0.4000), iterations=15, converged=True\n",
      "learning_rate=tensor(0.4100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.4900), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5000), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.5900), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6000), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.6900), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7000), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.7900), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8000), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.8900), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9000), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9100), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9200), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9300), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9400), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9500), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9600), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9700), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9800), iterations=1000, converged=False\n",
      "learning_rate=tensor(0.9900), iterations=1000, converged=False\n",
      "learning_rate=tensor(1.), iterations=1000, converged=False\n",
      "Fastest convergence using lr=0.3999999761581421 in 15 iterations\n"
     ]
    }
   ],
   "source": [
    "#Find best learning rate experimentally\n",
    "x0 = torch.tensor([1., 1, 1, 1, 1])\n",
    "learning_rates = torch.linspace(0.01, 1, 100)\n",
    "best_lr = None\n",
    "best_it = 9999999999\n",
    "for learning_rate in learning_rates:\n",
    "    x_star, iterations = gradient_descent(A, learning_rate, x0=deepcopy(x0))\n",
    "    converged = (iterations < 1000)\n",
    "    print(f\"{learning_rate=}, {iterations=}, {converged=}\")\n",
    "\n",
    "    #Update best learning rate\n",
    "    if iterations <= best_it:\n",
    "        best_lr = learning_rate\n",
    "        best_it = iterations\n",
    "print(f\"Fastest convergence using lr={best_lr} in {best_it} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(7.5000, grad_fn=<MulBackward0>), x=tensor([1., 1., 1., 1., 1.], requires_grad=True), x.grad=tensor([5., 4., 3., 2., 1.]), lr.item()=0.009999999776482582\n",
      "loss=tensor(0.0612, grad_fn=<MulBackward0>), x=tensor([2.9880e-04, 3.1261e-03, 1.9641e-02, 8.9311e-02, 3.2455e-01],\n",
      "       grad_fn=<SubBackward0>), x.grad=tensor([0.0015, 0.0125, 0.0589, 0.1786, 0.3246]), lr.item()=0.1293065845966339\n",
      "loss=tensor(0.0033, grad_fn=<MulBackward0>), x=tensor([8.5387e-09, 2.0719e-06, 1.4182e-04, 4.4272e-03, 8.0856e-02],\n",
      "       grad_fn=<SubBackward0>), x.grad=tensor([4.2694e-08, 8.2876e-06, 4.2547e-04, 8.8544e-03, 8.0856e-02]), lr.item()=0.12987931072711945\n",
      "loss=tensor(0.0002, grad_fn=<MulBackward0>), x=tensor([2.3888e-13, 1.3563e-09, 1.0166e-06, 2.1858e-04, 2.0109e-02],\n",
      "       grad_fn=<SubBackward0>), x.grad=tensor([1.1944e-12, 5.4251e-09, 3.0498e-06, 4.3715e-04, 2.0109e-02]), lr.item()=0.12990854680538177\n",
      "loss=tensor(1.2504e-05, grad_fn=<MulBackward0>), x=tensor([6.6750e-18, 8.8720e-13, 7.2841e-09, 1.0789e-05, 5.0008e-03],\n",
      "       grad_fn=<SubBackward0>), x.grad=tensor([3.3375e-17, 3.5488e-12, 2.1852e-08, 2.1578e-05, 5.0008e-03]), lr.item()=0.12991034984588623\n",
      "tensor([3.5283e-20, 2.2691e-14, 6.1657e-10, 2.3970e-06, 2.4938e-03],\n",
      "       grad_fn=<SubBackward0>) 45 tensor([0.1299], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def adaptive_lr_gd():\n",
    "    # Do gradient descent with adaptive learning rate.\n",
    "    x = deepcopy(x0)\n",
    "    x.requires_grad = True\n",
    "    precision = 1e-6\n",
    "    lr = torch.tensor([0.01], requires_grad=True)\n",
    "    lr_lr = 0.001\n",
    "    iterations = 0\n",
    "    prev_loss = 999999.99\n",
    "\n",
    "    while iterations < 100:\n",
    "        # Compute the loss\n",
    "        loss = quadratic_form(x, A)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if torch.abs(loss - prev_loss) < precision:\n",
    "            break\n",
    "        \n",
    "        # Update the parameters\n",
    "        x.grad = None\n",
    "        x.retain_grad()\n",
    "        lr.grad = None\n",
    "        loss.backward()\n",
    "        if iterations%10 == 0:\n",
    "            print(f\"{loss=}, {x=}, {x.grad=}, {lr.item()=}\")\n",
    "\n",
    "        #Update learning rate\n",
    "        if iterations > 0:\n",
    "            with torch.no_grad():\n",
    "                lr -= lr_lr * lr.grad\n",
    "\n",
    "        #Update x\n",
    "        x = x.detach() - lr * x.grad.detach()\n",
    "\n",
    "        iterations += 1\n",
    "        \n",
    "        # Update the previous loss\n",
    "        prev_loss = loss\n",
    "        \n",
    "    print(x, iterations, lr)\n",
    "\n",
    "adaptive_lr_gd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
