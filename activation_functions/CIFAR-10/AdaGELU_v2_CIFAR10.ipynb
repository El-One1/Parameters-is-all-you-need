{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time as time\n",
    "import numpy as np\n",
    "from gradient_descent_the_ultimate_optimizer import gdtuo\n",
    "from gradient_descent_the_ultimate_optimizer.gdtuo import Optimizable\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from IPython.display import Video, Image\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class adaGeLU(Optimizable):\n",
    "\n",
    "    def __init__(self, optimizer):\n",
    "\n",
    "        self.parameters = {'alpha': torch.tensor(1., requires_grad=True),\n",
    "                           'beta': torch.tensor(np.sqrt(2/np.pi), requires_grad=True),\n",
    "                           'gamma': torch.tensor(0.044715, requires_grad=True)}\n",
    "        self.optimizer = optimizer\n",
    "        self.all_params_with_gradients = [self.parameters['alpha'], self.parameters['beta'], self.parameters['gamma']]\n",
    "        \n",
    "        super().__init__(self.parameters, optimizer)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        output = (1/2) * input * (1 + F.tanh(self.parameters['beta'] * \n",
    "                                             (self.parameters['alpha']*input + \n",
    "                                              self.parameters['gamma']*(self.parameters['alpha']*input)**3)))\n",
    "        return output\n",
    "    \n",
    "    def step(self):\n",
    "        self.optimizer.step(self.parameters)\n",
    "\n",
    "\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(16384, 128)  # Adjusted input dimensions\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm1d(16384)\n",
    "\n",
    "        self.adaGeLU1 = None\n",
    "        self.adaGeLU2 = None\n",
    "        self.adaGeLU3 = None\n",
    "        self.dict_stats = {}\n",
    "        self.gather_stats = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1(x)\n",
    "        if self.gather_stats:\n",
    "            self.dict_stats['conv1_mean'] = x.clone().detach().cpu().numpy().mean()\n",
    "            self.dict_stats['conv1_std'] = x.clone().detach().cpu().numpy().std()\n",
    "        x = self.adaGeLU1(x)\n",
    "\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.gather_stats:\n",
    "            self.dict_stats['conv2_mean'] = x.clone().detach().cpu().numpy().mean()\n",
    "            self.dict_stats['conv2_std'] = x.clone().detach().cpu().numpy().std()\n",
    "        x = self.adaGeLU2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc1(x)\n",
    "        if self.gather_stats:\n",
    "            self.dict_stats['fc1_mean'] = x.clone().detach().cpu().numpy().mean()\n",
    "            self.dict_stats['fc1_std'] = x.clone().detach().cpu().numpy().std()\n",
    "        x = self.adaGeLU3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)\n",
    "\n",
    "dataset_train = torchvision.datasets.CIFAR10('./data_cifar', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "dataset_test = torchvision.datasets.CIFAR10('./data_cifar', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "dl_train = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(dataset_test, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "#optim = gdtuo.SGD(alpha=0.0769)\n",
    "model = MNIST_CNN()\n",
    "#model.load_state_dict(torch.load('../model/model_cifar.pt'))\n",
    "model.to(DEVICE)\n",
    "\n",
    "adaGelu1 = adaGeLU(gdtuo.Adam(alpha = 0.01))\n",
    "adaGelu2 = adaGeLU(gdtuo.Adam(alpha = 0.01))\n",
    "adaGelu3 = adaGeLU(gdtuo.Adam(alpha = 0.01))\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.adaGeLU1 = adaGelu1\n",
    "model.adaGeLU2 = adaGelu2\n",
    "model.adaGeLU3 = adaGelu3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#mw = gdtuo.ModuleWrapper(model, optimizer=optim)\n",
    "model.adaGeLU1.initialize()\n",
    "model.adaGeLU2.initialize()\n",
    "model.adaGeLU3.initialize()\n",
    "#mw.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, TRAIN LOSS: 1.487583603477478, ACC: 0.49228\n",
      "EPOCH: 1, TEST ACC: 0.6428\n",
      "\n",
      "EPOCH: 2, TRAIN LOSS: 1.0341383296585083, ACC: 0.63588\n",
      "EPOCH: 2, TEST ACC: 0.6805\n",
      "\n",
      "EPOCH: 3, TRAIN LOSS: 0.8782855855369568, ACC: 0.69244\n",
      "EPOCH: 3, TEST ACC: 0.702\n",
      "\n",
      "EPOCH: 4, TRAIN LOSS: 0.7605376928329468, ACC: 0.73098\n",
      "EPOCH: 4, TEST ACC: 0.718\n",
      "\n",
      "EPOCH: 5, TRAIN LOSS: 0.6676008232688904, ACC: 0.7629\n",
      "EPOCH: 5, TEST ACC: 0.7196\n",
      "\n",
      "EPOCH: 6, TRAIN LOSS: 0.5919881413936615, ACC: 0.78984\n",
      "EPOCH: 6, TEST ACC: 0.7288\n",
      "\n",
      "EPOCH: 7, TRAIN LOSS: 0.521190945854187, ACC: 0.81478\n",
      "EPOCH: 7, TEST ACC: 0.7242\n",
      "\n",
      "EPOCH: 8, TRAIN LOSS: 0.4684892978858948, ACC: 0.83106\n",
      "EPOCH: 8, TEST ACC: 0.7293\n",
      "\n",
      "EPOCH: 9, TRAIN LOSS: 0.42029150903701784, ACC: 0.8485\n",
      "EPOCH: 9, TEST ACC: 0.7312\n",
      "\n",
      "EPOCH: 10, TRAIN LOSS: 0.3856738301849365, ACC: 0.86236\n",
      "EPOCH: 10, TEST ACC: 0.7325\n",
      "\n",
      "Time taken: 87.60540199279785\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "EPOCHS = 10\n",
    "alpha1 = [model.adaGeLU1.parameters['alpha'].item()]\n",
    "beta1 = [model.adaGeLU1.parameters['beta'].item()]\n",
    "gamma1 = [model.adaGeLU1.parameters['gamma'].item()]\n",
    "alpha2 = [model.adaGeLU2.parameters['alpha'].item()]\n",
    "beta2 = [model.adaGeLU2.parameters['beta'].item()]\n",
    "gamma2 = [model.adaGeLU2.parameters['gamma'].item()]\n",
    "alpha3 = [model.adaGeLU3.parameters['alpha'].item()]\n",
    "beta3 = [model.adaGeLU3.parameters['beta'].item()]\n",
    "gamma3 = [model.adaGeLU3.parameters['gamma'].item()]\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for i in range(1, EPOCHS+1):\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for j, (features_, labels_) in enumerate(dl_train):\n",
    "        #mw.begin() # call this before each step, enables gradient tracking on desired params\n",
    "        model.adaGeLU1.begin()\n",
    "        model.adaGeLU2.begin()\n",
    "        model.adaGeLU3.begin()\n",
    "\n",
    "        optim.zero_grad()\n",
    "        features, labels = features_.to(DEVICE), labels_.to(DEVICE)\n",
    "        pred = model.forward(features)\n",
    "        loss = criterion(pred, labels)\n",
    "        #mw.zero_grad()\n",
    "        \n",
    "        loss.backward(create_graph=True) # important! use create_graph=True\n",
    "        #mw.step()\n",
    "        model.adaGeLU1.step()\n",
    "        model.adaGeLU2.step()\n",
    "        model.adaGeLU3.step()\n",
    "        model.adaGeLU1.zero_grad()\n",
    "        model.adaGeLU2.zero_grad()\n",
    "        model.adaGeLU3.zero_grad()\n",
    "        \n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item() * features_.size(0)\n",
    "        running_acc += (torch.argmax(pred, dim=1) == labels).sum().item()\n",
    "\n",
    "        if j%50 == 0:\n",
    "            alpha1.append(model.adaGeLU1.parameters['alpha'].item())\n",
    "            beta1.append(model.adaGeLU1.parameters['beta'].item())\n",
    "            gamma1.append(model.adaGeLU1.parameters['gamma'].item())\n",
    "            alpha2.append(model.adaGeLU2.parameters['alpha'].item())\n",
    "            beta2.append(model.adaGeLU2.parameters['beta'].item())\n",
    "            gamma2.append(model.adaGeLU2.parameters['gamma'].item())\n",
    "            alpha3.append(model.adaGeLU3.parameters['alpha'].item())\n",
    "            beta3.append(model.adaGeLU3.parameters['beta'].item())\n",
    "            gamma3.append(model.adaGeLU3.parameters['gamma'].item())\n",
    "    \n",
    "    train_loss = running_loss / len(dl_train.dataset)\n",
    "    train_acc = running_acc / len(dl_train.dataset)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for j, (features_, labels_) in enumerate(dl_test):\n",
    "            features, labels = features_.to(DEVICE), labels_.to(DEVICE)\n",
    "            pred = model.forward(features)\n",
    "            running_acc += (torch.argmax(pred, dim=1) == labels).sum().item()\n",
    "            loss = criterion(pred, labels)\n",
    "            running_loss += loss.item() * features_.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(dl_test.dataset)\n",
    "    test_acc = running_acc / len(dl_test.dataset)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(\"EPOCH: {}, TRAIN LOSS: {}, ACC: {}\".format(i, train_loss, train_acc))\n",
    "    print(\"EPOCH: {}, TEST ACC: {}\\n\".format(i, test_acc))\n",
    "    \n",
    "print(\"Time taken: {}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training and testing statistics in csv\n",
    "path = '../results/CIFAR-10'\n",
    "name = 'adagelu'\n",
    "np.savetxt(path + '/' + name + '_train_loss.csv', train_loss_list, delimiter=',')\n",
    "np.savetxt(path + '/' + name + '_train_acc.csv', train_acc_list, delimiter=',')\n",
    "np.savetxt(path + '/' + name + '_test_loss.csv', test_loss_list, delimiter=',')\n",
    "np.savetxt(path + '/' + name + '_test_acc.csv', test_acc_list, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_520483/3752407317.py:29: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  imageio.mimsave(video, [imageio.imread('plots/{}.png'.format(i)) for i in range(len(beta1))], fps = 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./adaGELU.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(beta1)):\n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    y_baseline = F.gelu(torch.tensor(x)).numpy()\n",
    "    x = torch.tensor(x)\n",
    "    y1 = (1/2) * x * (1 + F.tanh(beta1[i] * (alpha1[i]*x + gamma1[i] * (alpha1[i]*x**3)))).numpy()\n",
    "    y2 = (1/2) * x * (1 + F.tanh(beta2[i] * (alpha2[i]*x + gamma2[i] * (alpha2[i]*x**3)))).numpy()\n",
    "    y3 = (1/2) * x * (1 + F.tanh(beta3[i] * (alpha3[i]*x + gamma3[i] * (alpha3[i]*x**3)))).numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y_baseline)\n",
    "    ax.plot(x, y1)\n",
    "    ax.plot(x, y2)\n",
    "    ax.plot(x, y3)\n",
    "    # set small cross at 0.0\n",
    "    ax.plot([0.0], [0.0], 'x', color='red')\n",
    "    ax.set_title('AdaGELU on all activations for CIFAR10 beats GeLU and ReLU')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "\n",
    "    ax.legend(['baseline (gelu)', 'adagelu 1', 'adagelu 2', 'adagelu 3'])\n",
    "    ax.set_xlim([-10, 10])\n",
    "    ax.set_ylim([-3, 10])\n",
    "    ax.grid()\n",
    "\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    plt.savefig('plots/{}.png'.format(i))\n",
    "    plt.close()\n",
    "\n",
    "video = './adaGELU.mp4'\n",
    "imageio.mimsave(video, [imageio.imread('plots/{}.png'.format(i)) for i in range(len(beta1))], fps = 4)\n",
    "#play it here\n",
    "Video(video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
